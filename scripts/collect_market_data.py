#!/usr/bin/env python3
"""
å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

yfinanceã‚’ä½¿ç”¨ã—ã¦ç„¡æ–™ã§æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»ä¿å­˜
- æ—¥æœ¬æ ªï¼ˆNikkei 225ä¸»è¦éŠ˜æŸ„ï¼‰
- ç±³å›½æ ªï¼ˆS&P 500ä¸»è¦éŠ˜æŸ„ï¼‰  
- ä¸»è¦ETFã€æŒ‡æ•°
- ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆ

è§£æã¨ã¯åˆ†é›¢ã—ã¦ã€ç¢ºå®Ÿãªãƒ‡ãƒ¼ã‚¿åé›†ãƒ»ä¿å­˜ã‚’å®Ÿè¡Œ
"""

import sys
import os
from pathlib import Path
import time
from datetime import datetime, timedelta
import traceback
import json

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
SRC_DIR = PROJECT_ROOT / "src"
sys.path.insert(0, str(SRC_DIR))

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
DATA_DIR = PROJECT_ROOT / "data"
RAW_DATA_DIR = DATA_DIR / "raw"
PROCESSED_DATA_DIR = DATA_DIR / "processed"

RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)
PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)

import yfinance as yf
import pandas as pd
import numpy as np

def get_nikkei_225_symbols():
    """æ—¥çµŒ225ä¸»è¦éŠ˜æŸ„ãƒªã‚¹ãƒˆï¼ˆæ±è¨¼ãƒ—ãƒ©ã‚¤ãƒ ï¼‰"""
    # ä¸»è¦ãªæ—¥æœ¬æ ªéŠ˜æŸ„ï¼ˆ.T ã¯æ±äº¬è¨¼åˆ¸å–å¼•æ‰€ï¼‰
    symbols = [
        # è‡ªå‹•è»Šãƒ»è¼¸é€æ©Ÿå™¨
        "7203.T",  # ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š
        "7267.T",  # ãƒ›ãƒ³ãƒ€
        "7201.T",  # æ—¥ç”£è‡ªå‹•è»Š
        "7269.T",  # ã‚¹ã‚ºã‚­
        
        # é›»æ©Ÿãƒ»ç²¾å¯†æ©Ÿå™¨
        "6758.T",  # ã‚½ãƒ‹ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—
        "6861.T",  # ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹
        "7974.T",  # ä»»å¤©å ‚
        "6954.T",  # ãƒ•ã‚¡ãƒŠãƒƒã‚¯
        "6981.T",  # æ‘ç”°è£½ä½œæ‰€
        
        # æƒ…å ±ãƒ»é€šä¿¡
        "9984.T",  # ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—
        "4689.T",  # Zãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
        "9613.T",  # ã‚¨ãƒŒãƒ»ãƒ†ã‚£ãƒ»ãƒ†ã‚£ãƒ»ãƒ‡ãƒ¼ã‚¿
        "9432.T",  # æ—¥æœ¬é›»ä¿¡é›»è©±
        
        # éŠ€è¡Œãƒ»è¨¼åˆ¸ãƒ»ä¿é™º
        "8306.T",  # ä¸‰è±UFJãƒ•ã‚£ãƒŠãƒ³ã‚·ãƒ£ãƒ«ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—
        "8316.T",  # ä¸‰äº•ä½å‹ãƒ•ã‚£ãƒŠãƒ³ã‚·ãƒ£ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—
        "8411.T",  # ã¿ãšã»ãƒ•ã‚£ãƒŠãƒ³ã‚·ãƒ£ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—
        "8604.T",  # é‡æ‘ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
        
        # å°å£²ãƒ»ã‚µãƒ¼ãƒ“ã‚¹
        "9983.T",  # ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒªãƒ†ã‚¤ãƒªãƒ³ã‚°
        "3382.T",  # ã‚»ãƒ–ãƒ³&ã‚¢ã‚¤ãƒ»ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
        "8267.T",  # ã‚¤ã‚ªãƒ³
        "9843.T",  # ãƒ‹ãƒˆãƒªãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
        
        # ç´ æãƒ»åŒ–å­¦
        "4063.T",  # ä¿¡è¶ŠåŒ–å­¦å·¥æ¥­
        "4502.T",  # æ­¦ç”°è–¬å“å·¥æ¥­
        "4519.T",  # ä¸­å¤–è£½è–¬
        "5401.T",  # æ–°æ—¥éµä½é‡‘
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»å•†ç¤¾
        "8058.T",  # ä¸‰è±å•†äº‹
        "8031.T",  # ä¸‰äº•ç‰©ç”£
        "8053.T",  # ä½å‹å•†äº‹
        "1605.T",  # å›½éš›çŸ³æ²¹é–‹ç™ºå¸çŸ³
        
        # ä¸å‹•ç”£ãƒ»å»ºè¨­
        "1925.T",  # å¤§å’Œãƒã‚¦ã‚¹å·¥æ¥­
        "1802.T",  # å¤§æ—çµ„
        "8804.T",  # æ±äº¬å»ºç‰©
    ]
    
    return symbols

def get_sp500_symbols():
    """S&P500ä¸»è¦éŠ˜æŸ„ãƒªã‚¹ãƒˆ"""
    symbols = [
        # ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼
        "AAPL",   # Apple
        "MSFT",   # Microsoft
        "GOOGL",  # Alphabet
        "AMZN",   # Amazon
        "TSLA",   # Tesla
        "META",   # Meta
        "NVDA",   # NVIDIA
        "NFLX",   # Netflix
        
        # é‡‘è
        "JPM",    # JPMorgan Chase
        "BAC",    # Bank of America
        "WFC",    # Wells Fargo
        "GS",     # Goldman Sachs
        
        # ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢
        "JNJ",    # Johnson & Johnson
        "PFE",    # Pfizer
        "UNH",    # UnitedHealth
        "ABBV",   # AbbVie
        
        # æ¶ˆè²»è²¡
        "PG",     # Procter & Gamble
        "KO",     # Coca-Cola
        "PEP",    # PepsiCo
        "WMT",    # Walmart
        
        # å·¥æ¥­
        "BA",     # Boeing
        "CAT",    # Caterpillar
        "GE",     # General Electric
        "MMM",    # 3M
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼
        "XOM",    # Exxon Mobil
        "CVX",    # Chevron
    ]
    
    return symbols

def get_market_indices():
    """ä¸»è¦æŒ‡æ•°ãƒ»ETFãƒªã‚¹ãƒˆ"""
    indices = {
        # æ—¥æœ¬
        "^N225": "Nikkei 225",
        "^TOPX": "TOPIX",
        "1306.T": "TOPIXé€£å‹•å‹ä¸Šå ´æŠ•è³‡ä¿¡è¨—",
        
        # ç±³å›½
        "^GSPC": "S&P 500",
        "^DJI": "Dow Jones",
        "^IXIC": "NASDAQ",
        "SPY": "SPDR S&P 500 ETF",
        "QQQ": "Invesco QQQ Trust",
        "VTI": "Vanguard Total Stock Market ETF",
        
        # ä¸–ç•Œ
        "VT": "Vanguard Total World Stock ETF",
        "VEA": "Vanguard FTSE Developed Markets ETF",
        "VWO": "Vanguard FTSE Emerging Markets ETF",
        
        # å‚µåˆ¸
        "TLT": "iShares 20+ Year Treasury Bond ETF",
        "IEF": "iShares 7-10 Year Treasury Bond ETF",
        
        # å•†å“
        "GLD": "SPDR Gold Shares",
        "SLV": "iShares Silver Trust",
        "USO": "United States Oil Fund",
    }
    
    return indices

def get_forex_pairs():
    """ä¸»è¦ç‚ºæ›¿ãƒšã‚¢"""
    pairs = {
        "USDJPY=X": "USD/JPY",
        "EURJPY=X": "EUR/JPY", 
        "GBPJPY=X": "GBP/JPY",
        "AUDJPY=X": "AUD/JPY",
        "EURUSD=X": "EUR/USD",
        "GBPUSD=X": "GBP/USD",
        "AUDUSD=X": "AUD/USD",
    }
    
    return pairs

def download_stock_data(symbols, period="2y", interval="1d", market_name="stocks"):
    """
    æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    
    Args:
        symbols: ã‚·ãƒ³ãƒœãƒ«ãƒªã‚¹ãƒˆ
        period: æœŸé–“ ("1d", "5d", "1mo", "3mo", "6mo", "1y", "2y", "5y", "10y", "ytd", "max")
        interval: é–“éš” ("1m", "2m", "5m", "15m", "30m", "60m", "90m", "1h", "1d", "5d", "1wk", "1mo", "3mo")
        market_name: å¸‚å ´åï¼ˆä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰
    """
    
    print(f"\nğŸ”„ {market_name}ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
    print(f"éŠ˜æŸ„æ•°: {len(symbols)}, æœŸé–“: {period}, é–“éš”: {interval}")
    
    all_data = {}
    success_count = 0
    error_count = 0
    errors = []
    
    for i, symbol in enumerate(symbols, 1):
        try:
            print(f"[{i}/{len(symbols)}] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {symbol}")
            
            # yfinanceã§ãƒ‡ãƒ¼ã‚¿å–å¾—
            ticker = yf.Ticker(symbol)
            hist = ticker.history(period=period, interval=interval)
            
            if hist.empty:
                print(f"âš ï¸  {symbol}: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                error_count += 1
                errors.append(f"{symbol}: Empty data")
                continue
            
            # åŸºæœ¬æƒ…å ±ã‚‚å–å¾—
            info = {}
            try:
                ticker_info = ticker.info
                info = {
                    'symbol': symbol,
                    'shortName': ticker_info.get('shortName', 'N/A'),
                    'longName': ticker_info.get('longName', 'N/A'),
                    'currency': ticker_info.get('currency', 'N/A'),
                    'exchange': ticker_info.get('exchange', 'N/A'),
                    'country': ticker_info.get('country', 'N/A'),
                    'sector': ticker_info.get('sector', 'N/A'),
                    'industry': ticker_info.get('industry', 'N/A'),
                    'marketCap': ticker_info.get('marketCap', 'N/A'),
                    'download_date': datetime.now().isoformat(),
                    'data_start': hist.index.min().isoformat(),
                    'data_end': hist.index.max().isoformat(),
                    'data_points': len(hist)
                }
            except Exception as e:
                print(f"âš ï¸  {symbol}: åŸºæœ¬æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ - {e}")
                info = {
                    'symbol': symbol,
                    'download_date': datetime.now().isoformat(),
                    'data_start': hist.index.min().isoformat(),
                    'data_end': hist.index.max().isoformat(),
                    'data_points': len(hist),
                    'info_error': str(e)
                }
            
            all_data[symbol] = {
                'price_data': hist,
                'info': info
            }
            
            success_count += 1
            print(f"âœ… {symbol}: {len(hist)}æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            time.sleep(0.1)
            
        except Exception as e:
            print(f"âŒ {symbol}: ã‚¨ãƒ©ãƒ¼ - {e}")
            error_count += 1
            errors.append(f"{symbol}: {str(e)}")
            continue
    
    print(f"\nğŸ“Š {market_name}ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    print(f"âœ… æˆåŠŸ: {success_count}éŠ˜æŸ„")
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error_count}éŠ˜æŸ„")
    
    if errors:
        print("\nâš ï¸ ã‚¨ãƒ©ãƒ¼è©³ç´°:")
        for error in errors[:5]:  # æœ€åˆã®5å€‹ã®ã‚¨ãƒ©ãƒ¼ã®ã¿è¡¨ç¤º
            print(f"  - {error}")
        if len(errors) > 5:
            print(f"  ... ä»–{len(errors)-5}å€‹ã®ã‚¨ãƒ©ãƒ¼")
    
    return all_data, {'success': success_count, 'errors': error_count, 'error_list': errors}

def save_market_data(data_dict, market_name, period, interval):
    """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # å„éŠ˜æŸ„ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ä¿å­˜
    price_data_dir = RAW_DATA_DIR / f"{market_name}_{period}_{interval}" / "price_data"
    price_data_dir.mkdir(parents=True, exist_ok=True)
    
    # éŠ˜æŸ„æƒ…å ±ã‚’JSONã§ä¿å­˜
    info_file = RAW_DATA_DIR / f"{market_name}_{period}_{interval}" / f"symbols_info_{timestamp}.json"
    info_file.parent.mkdir(parents=True, exist_ok=True)
    
    # çµ±åˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå…¨éŠ˜æŸ„ã®çµ‚å€¤ï¼‰
    all_closes = {}
    all_volumes = {}
    symbols_info = {}
    
    for symbol, data in data_dict.items():
        # å€‹åˆ¥ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        price_file = price_data_dir / f"{symbol.replace('.', '_').replace('=', '_').replace('^', '')}.csv"
        data['price_data'].to_csv(price_file)
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ç”¨
        if 'Close' in data['price_data'].columns:
            all_closes[symbol] = data['price_data']['Close']
        if 'Volume' in data['price_data'].columns:
            all_volumes[symbol] = data['price_data']['Volume']
        
        # éŠ˜æŸ„æƒ…å ±
        symbols_info[symbol] = data['info']
    
    # çµ±åˆçµ‚å€¤ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    if all_closes:
        closes_df = pd.DataFrame(all_closes)
        closes_file = RAW_DATA_DIR / f"{market_name}_{period}_{interval}" / f"all_closes_{timestamp}.csv"
        closes_df.to_csv(closes_file)
        print(f"ğŸ’¾ çµ±åˆçµ‚å€¤ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {closes_file}")
    
    # çµ±åˆå‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    if all_volumes:
        volumes_df = pd.DataFrame(all_volumes)
        volumes_file = RAW_DATA_DIR / f"{market_name}_{period}_{interval}" / f"all_volumes_{timestamp}.csv"
        volumes_df.to_csv(volumes_file)
        print(f"ğŸ’¾ çµ±åˆå‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {volumes_file}")
    
    # éŠ˜æŸ„æƒ…å ±JSON
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(symbols_info, f, indent=2, ensure_ascii=False, default=str)
    print(f"ğŸ’¾ éŠ˜æŸ„æƒ…å ±ä¿å­˜: {info_file}")
    
    return {
        'price_data_dir': str(price_data_dir),
        'closes_file': str(closes_file) if all_closes else None,
        'volumes_file': str(volumes_file) if all_volumes else None,
        'info_file': str(info_file)
    }

def create_data_summary():
    """åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼ä½œæˆ"""
    
    summary = {
        'collection_date': datetime.now().isoformat(),
        'data_directories': [],
        'total_symbols': 0,
        'markets_covered': []
    }
    
    # data/rawãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³
    for market_dir in RAW_DATA_DIR.iterdir():
        if market_dir.is_dir():
            price_data_dir = market_dir / "price_data"
            if price_data_dir.exists():
                csv_files = list(price_data_dir.glob("*.csv"))
                
                market_info = {
                    'market_name': market_dir.name,
                    'symbol_count': len(csv_files),
                    'csv_files': [f.name for f in csv_files],
                    'directory': str(market_dir)
                }
                
                summary['data_directories'].append(market_info)
                summary['total_symbols'] += len(csv_files)
                summary['markets_covered'].append(market_dir.name)
    
    # ã‚µãƒãƒªãƒ¼ä¿å­˜
    summary_file = DATA_DIR / f"data_collection_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿åé›†ã‚µãƒãƒªãƒ¼: {summary_file}")
    print(f"ç·éŠ˜æŸ„æ•°: {summary['total_symbols']}")
    print(f"å¸‚å ´æ•°: {len(summary['markets_covered'])}")
    
    return summary

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("ğŸš€ å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
    print("=" * 60)
    
    collection_results = {}
    
    try:
        # 1. æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿åé›†
        nikkei_symbols = get_nikkei_225_symbols()
        jp_data, jp_stats = download_stock_data(
            nikkei_symbols, 
            period="2y", 
            interval="1d", 
            market_name="japanese_stocks"
        )
        
        if jp_data:
            jp_files = save_market_data(jp_data, "japanese_stocks", "2y", "1d")
            collection_results['japanese_stocks'] = {
                'stats': jp_stats,
                'files': jp_files,
                'symbols': list(jp_data.keys())
            }
        
        # 2. ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿åé›†
        sp500_symbols = get_sp500_symbols()
        us_data, us_stats = download_stock_data(
            sp500_symbols,
            period="2y",
            interval="1d", 
            market_name="us_stocks"
        )
        
        if us_data:
            us_files = save_market_data(us_data, "us_stocks", "2y", "1d")
            collection_results['us_stocks'] = {
                'stats': us_stats,
                'files': us_files,
                'symbols': list(us_data.keys())
            }
        
        # 3. æŒ‡æ•°ãƒ»ETFãƒ‡ãƒ¼ã‚¿åé›†
        indices = get_market_indices()
        index_data, index_stats = download_stock_data(
            list(indices.keys()),
            period="2y",
            interval="1d",
            market_name="indices_etfs"
        )
        
        if index_data:
            index_files = save_market_data(index_data, "indices_etfs", "2y", "1d")
            collection_results['indices_etfs'] = {
                'stats': index_stats,
                'files': index_files,
                'symbols': list(index_data.keys())
            }
        
        # 4. ç‚ºæ›¿ãƒ‡ãƒ¼ã‚¿åé›†
        forex_pairs = get_forex_pairs()
        forex_data, forex_stats = download_stock_data(
            list(forex_pairs.keys()),
            period="2y",
            interval="1d",
            market_name="forex"
        )
        
        if forex_data:
            forex_files = save_market_data(forex_data, "forex", "2y", "1d")
            collection_results['forex'] = {
                'stats': forex_stats,
                'files': forex_files,
                'symbols': list(forex_data.keys())
            }
        
        # 5. å…¨ä½“ã‚µãƒãƒªãƒ¼ä½œæˆ
        summary = create_data_summary()
        
        # 6. åé›†çµæœãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        results_file = DATA_DIR / f"collection_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(collection_results, f, indent=2, ensure_ascii=False, default=str)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
        print("=" * 60)
        
        total_success = sum(result['stats']['success'] for result in collection_results.values())
        total_errors = sum(result['stats']['errors'] for result in collection_results.values())
        
        print(f"âœ… ç·æˆåŠŸéŠ˜æŸ„æ•°: {total_success}")
        print(f"âŒ ç·ã‚¨ãƒ©ãƒ¼éŠ˜æŸ„æ•°: {total_errors}")
        print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆ: {DATA_DIR}")
        print(f"ğŸ“Š åé›†çµæœ: {results_file}")
        
        return True
        
    except Exception as e:
        print(f"\nğŸ’¥ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"è©³ç´°: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)