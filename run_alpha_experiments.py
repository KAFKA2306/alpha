#!/usr/bin/env python3
"""
Alpha Architecture Agent - åŒ…æ‹¬çš„å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹æ ªä¾¡äºˆæ¸¬ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¢ç´¢ã®
å…¨å®Ÿé¨“ã‚’çµ±æ‹¬ã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚

ç›®æ¨™:
- å€‹åˆ¥æˆ¦ç•¥ã®ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª 1.3ä»¥ä¸Šé”æˆ
- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã®ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª 2.0ä»¥ä¸Šé”æˆ  
- å¤šæ§˜ãªæŠ•è³‡æˆ¦ç•¥ã®é‡ç”£ã¨åˆ†æ•£é‹ç”¨
- æ—¥æœ¬æ ªå¸‚å ´ã§ã®å®Ÿè¨¼å®Ÿé¨“

å®Ÿé¨“ãƒ•ã‚§ãƒ¼ã‚º:
1. äººå·¥å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ»æ¤œè¨¼
2. AIã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆãƒ»è©•ä¾¡
3. äºˆæ¸¬æ€§èƒ½è©•ä¾¡ãƒ»æœ€é©åŒ–
4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥æ§‹ç¯‰ãƒ»æ¤œè¨¼
5. ç·åˆåˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import sys
import os
from pathlib import Path
import warnings
import traceback
from datetime import datetime, timedelta
import json
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¨­å®š
PROJECT_ROOT = Path(__file__).parent
SRC_DIR = PROJECT_ROOT / "src"
sys.path.insert(0, str(SRC_DIR))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('alpha_experiments.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

warnings.filterwarnings('ignore')

# å®Ÿé¨“è¨­å®šã‚¯ãƒ©ã‚¹
@dataclass
class AlphaExperimentConfig:
    """åŒ…æ‹¬çš„å®Ÿé¨“è¨­å®š"""
    # å®Ÿé¨“åŸºæœ¬è¨­å®š
    experiment_name: str = "alpha_architecture_exploration_v1"
    output_dir: str = "experiments/alpha_results"
    seed: int = 42
    
    # å¸‚å ´ãƒ‡ãƒ¼ã‚¿è¨­å®šï¼ˆæ—¥æœ¬æ ªå¸‚å ´æƒ³å®šï¼‰
    n_stocks: int = 100
    n_days: int = 2016  # 8å¹´é–“ï¼ˆ2017-2024å¹´ç›¸å½“ï¼‰
    n_features: int = 20
    start_date: str = "2017-01-01"
    
    # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆè¨­å®š
    n_architectures: int = 70  # å¤šæ§˜ãªæˆ¦ç•¥é‡ç”£
    input_shape: Tuple[int, int, int] = (32, 252, 20)  # batch, seq, features
    max_blocks_per_arch: int = 12
    
    # å­¦ç¿’ãƒ»è©•ä¾¡è¨­å®š
    train_split: float = 0.5   # 4å¹´ï¼šå­¦ç¿’æœŸé–“
    val_split: float = 0.25    # 2å¹´ï¼šæ¤œè¨¼æœŸé–“
    test_split: float = 0.25   # 2å¹´ï¼šè©•ä¾¡æœŸé–“
    
    # ç›®æ¨™æ€§èƒ½æŒ‡æ¨™
    target_individual_sharpe: float = 1.3
    target_ensemble_sharpe: float = 2.0
    target_max_drawdown: float = 0.10
    target_win_rate: float = 0.60
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
    top_performers_count: int = 20
    ensemble_methods: List[str] = None
    
    # å®Ÿé¨“åˆ¶å¾¡
    enable_llm_generation: bool = True
    enable_gpu: bool = True
    parallel_evaluation: bool = False
    save_intermediate_results: bool = True
    
    def __post_init__(self):
        if self.ensemble_methods is None:
            self.ensemble_methods = [
                'equal_weight',
                'sharpe_weighted', 
                'diversity_weighted',
                'risk_adjusted',
                'momentum_based'
            ]


class AlphaExperimentRunner:
    """Alpha Architecture Agentå®Ÿé¨“çµ±æ‹¬ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: AlphaExperimentConfig = None):
        self.config = config or AlphaExperimentConfig()
        self.results = {}
        self.experiment_start_time = datetime.now()
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_dir = Path(self.config.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å®Ÿé¨“çŠ¶æ…‹ç®¡ç†
        self.phase_results = {}
        self.generated_architectures = []
        self.market_data = None
        self.performance_results = []
        self.ensemble_results = {}
        
        logger.info(f"Alpha Architecture Agentå®Ÿé¨“ã‚’é–‹å§‹")
        logger.info(f"å®Ÿé¨“å: {self.config.experiment_name}")
        logger.info(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        logger.info(f"ç›®æ¨™: å€‹åˆ¥æˆ¦ç•¥Sharpe>{self.config.target_individual_sharpe}, "
                   f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«Sharpe>{self.config.target_ensemble_sharpe}")
    
    def run_comprehensive_experiment(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„å®Ÿé¨“ã®å®Ÿè¡Œ"""
        
        logger.info("=" * 80)
        logger.info("ğŸš€ ALPHA ARCHITECTURE AGENT - åŒ…æ‹¬çš„å®Ÿé¨“é–‹å§‹")
        logger.info("=" * 80)
        
        try:
            # ãƒ•ã‚§ãƒ¼ã‚º1: ç’°å¢ƒæ¤œè¨¼ãƒ»åˆæœŸåŒ–
            self._phase1_environment_validation()
            
            # ãƒ•ã‚§ãƒ¼ã‚º2: äººå·¥å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            self._phase2_synthetic_market_generation()
            
            # ãƒ•ã‚§ãƒ¼ã‚º3: AIã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ
            self._phase3_architecture_generation()
            
            # ãƒ•ã‚§ãƒ¼ã‚º4: äºˆæ¸¬æ€§èƒ½è©•ä¾¡
            self._phase4_performance_evaluation()
            
            # ãƒ•ã‚§ãƒ¼ã‚º5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥æ§‹ç¯‰
            self._phase5_ensemble_construction()
            
            # ãƒ•ã‚§ãƒ¼ã‚º6: ç·åˆåˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆ
            final_report = self._phase6_comprehensive_analysis()
            
            # å®Ÿé¨“å®Œäº†
            self._finalize_experiment()
            
            return final_report
            
        except Exception as e:
            logger.error(f"å®Ÿé¨“å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            traceback.print_exc()
            return {"status": "failed", "error": str(e)}
    
    def _phase1_environment_validation(self):
        """ãƒ•ã‚§ãƒ¼ã‚º1: ç’°å¢ƒæ¤œè¨¼ãƒ»åˆæœŸåŒ–"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ ãƒ•ã‚§ãƒ¼ã‚º1: ç’°å¢ƒæ¤œè¨¼ãƒ»åˆæœŸåŒ–")
        logger.info("=" * 60)
        
        # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
        self._validate_dependencies()
        
        # GPUåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        self._check_gpu_availability()
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯æ¤œè¨¼
        self._validate_domain_blocks()
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        self._validate_configurations()
        
        self.phase_results['phase1'] = {
            'status': 'completed',
            'timestamp': datetime.now().isoformat(),
            'validation_passed': True
        }
        
        logger.info("âœ… ãƒ•ã‚§ãƒ¼ã‚º1å®Œäº†: ç’°å¢ƒæ¤œè¨¼æˆåŠŸ")
    
    def _phase2_synthetic_market_generation(self):
        """ãƒ•ã‚§ãƒ¼ã‚º2: äººå·¥å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š ãƒ•ã‚§ãƒ¼ã‚º2: äººå·¥å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
        logger.info("=" * 60)
        
        try:
            from data.synthetic_market import SyntheticMarketGenerator, MarketConfig, create_market_scenarios
            
            # å¸‚å ´ã‚·ãƒŠãƒªã‚ªç”Ÿæˆ
            scenarios = create_market_scenarios()
            scenario_data = {}
            
            logger.info(f"ç”Ÿæˆã™ã‚‹å¸‚å ´ã‚·ãƒŠãƒªã‚ª: {list(scenarios.keys())}")
            
            for scenario_name, market_config in scenarios.items():
                logger.info(f"\nğŸ“ˆ {scenario_name}å¸‚å ´ã‚·ãƒŠãƒªã‚ªç”Ÿæˆä¸­...")
                
                # å®Ÿé¨“è¨­å®šã«åˆã‚ã›ã¦èª¿æ•´
                market_config.n_stocks = self.config.n_stocks
                market_config.n_days = self.config.n_days
                market_config.n_features = self.config.n_features
                market_config.start_date = self.config.start_date
                
                # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                generator = SyntheticMarketGenerator(market_config)
                data = generator.generate_market_data(seed=self.config.seed + hash(scenario_name) % 1000)
                
                # ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼
                quality_metrics = self._validate_market_data(data, scenario_name)
                
                scenario_data[scenario_name] = {
                    'data': data,
                    'config': asdict(market_config),
                    'quality': quality_metrics
                }
                
                logger.info(f"âœ… {scenario_name}: å“è³ªã‚¹ã‚³ã‚¢ {quality_metrics['quality_score']:.3f}")
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒŠãƒªã‚ªè¨­å®šï¼ˆå®‰å®šå¸‚å ´ã‚’ä½¿ç”¨ï¼‰
            self.market_data = scenario_data['stable']['data']
            
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            self._save_market_data(scenario_data)
            
            self.phase_results['phase2'] = {
                'status': 'completed',
                'timestamp': datetime.now().isoformat(),
                'scenarios_generated': len(scenarios),
                'data_quality_avg': np.mean([s['quality']['quality_score'] for s in scenario_data.values()]),
                'market_properties': self._analyze_market_properties(self.market_data)
            }
            
            logger.info(f"âœ… ãƒ•ã‚§ãƒ¼ã‚º2å®Œäº†: {len(scenarios)}ã‚·ãƒŠãƒªã‚ªã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæˆåŠŸ")
            
        except Exception as e:
            logger.error(f"å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _phase3_architecture_generation(self):
        """ãƒ•ã‚§ãƒ¼ã‚º3: AIã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ¤– ãƒ•ã‚§ãƒ¼ã‚º3: AIã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ")
        logger.info("=" * 60)
        
        try:
            from agents.architecture_agent import ArchitectureAgent
            from models.domain_blocks import get_domain_block_registry
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ç¢ºèª
            registry = get_domain_block_registry()
            total_blocks = len(registry.get_all_blocks())
            categories = registry.get_categories()
            
            logger.info(f"åˆ©ç”¨å¯èƒ½ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯: {total_blocks}å€‹")
            logger.info(f"ã‚«ãƒ†ã‚´ãƒª: {', '.join(categories)}")
            
            # AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–
            try:
                if self.config.enable_llm_generation:
                    agent = ArchitectureAgent()
                    logger.info("âœ… LLMå¯¾å¿œAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–æˆåŠŸ")
                else:
                    raise Exception("LLMç„¡åŠ¹è¨­å®š")
            except Exception as e:
                logger.warning(f"LLMåˆæœŸåŒ–å¤±æ•—: {e}")
                logger.info("ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆå™¨ã‚’ä½¿ç”¨")
                agent = ArchitectureAgent(generator=None)
            
            # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ
            logger.info(f"\nğŸ—ï¸ {self.config.n_architectures}å€‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆä¸­...")
            
            architectures = agent.generate_architecture_suite(
                input_shape=self.config.input_shape,
                num_architectures=self.config.n_architectures,
                max_blocks=self.config.max_blocks_per_arch
            )
            
            self.generated_architectures = architectures
            generation_success_rate = len(architectures) / self.config.n_architectures
            
            # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤šæ§˜æ€§åˆ†æ
            diversity_metrics = self._analyze_architecture_diversity(architectures)
            
            # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¿å­˜
            self._save_architectures(architectures)
            
            self.phase_results['phase3'] = {
                'status': 'completed',
                'timestamp': datetime.now().isoformat(),
                'architectures_generated': len(architectures),
                'generation_success_rate': generation_success_rate,
                'diversity_metrics': diversity_metrics,
                'total_blocks_available': total_blocks
            }
            
            logger.info(f"âœ… ãƒ•ã‚§ãƒ¼ã‚º3å®Œäº†: {len(architectures)}å€‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ")
            logger.info(f"   æˆåŠŸç‡: {generation_success_rate:.1%}")
            logger.info(f"   å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢: {diversity_metrics['avg_diversity']:.3f}")
            
        except Exception as e:
            logger.error(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _phase4_performance_evaluation(self):
        """ãƒ•ã‚§ãƒ¼ã‚º4: äºˆæ¸¬æ€§èƒ½è©•ä¾¡"""
        logger.info("\n" + "=" * 60)
        logger.info("âš¡ ãƒ•ã‚§ãƒ¼ã‚º4: äºˆæ¸¬æ€§èƒ½è©•ä¾¡")
        logger.info("=" * 60)
        
        try:
            from experiments.experiment_runner import ArchitecturePerformanceEvaluator, ExperimentConfig
            
            # è©•ä¾¡å™¨åˆæœŸåŒ–
            eval_config = ExperimentConfig(
                n_stocks=self.config.n_stocks,
                n_days=self.config.n_days,
                n_features=self.config.n_features,
                input_shape=self.config.input_shape,
                train_split=self.config.train_split,
                val_split=self.config.val_split,
                test_split=self.config.test_split
            )
            
            evaluator = ArchitecturePerformanceEvaluator(eval_config)
            
            # å„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ€§èƒ½è©•ä¾¡
            logger.info(f"ğŸ“Š {len(self.generated_architectures)}å€‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©•ä¾¡ä¸­...")
            
            evaluation_results = []
            successful_evaluations = 0
            
            for i, arch in enumerate(self.generated_architectures):
                logger.info(f"è©•ä¾¡ä¸­ ({i+1}/{len(self.generated_architectures)}): {arch.name}")
                
                # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä»•æ§˜ä½œæˆ
                arch_spec = {
                    'id': arch.id,
                    'name': arch.name,
                    'blocks': arch.blocks,
                    'metadata': arch.metadata,
                    'complexity_score': arch.complexity_score,
                    'diversity_score': arch.diversity_score
                }
                
                # æ€§èƒ½è©•ä¾¡å®Ÿè¡Œ
                performance = evaluator.evaluate_architecture(arch_spec, self.market_data)
                evaluation_results.append(performance)
                
                if 'error' not in performance:
                    successful_evaluations += 1
                    logger.info(f"   âœ… Sharpe: {performance['sharpe_ratio']:.3f}, "
                              f"Win Rate: {performance['win_rate']:.3f}, "
                              f"Drawdown: {performance['max_drawdown']:.3f}")
                else:
                    logger.warning(f"   âŒ è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {performance['error'][:50]}...")
            
            self.performance_results = evaluation_results
            successful_results = [r for r in evaluation_results if 'error' not in r]
            
            # æ€§èƒ½çµ±è¨ˆè¨ˆç®—
            if successful_results:
                performance_stats = self._calculate_performance_statistics(successful_results)
                
                self.phase_results['phase4'] = {
                    'status': 'completed',
                    'timestamp': datetime.now().isoformat(),
                    'total_evaluations': len(evaluation_results),
                    'successful_evaluations': successful_evaluations,
                    'success_rate': successful_evaluations / len(evaluation_results),
                    'performance_stats': performance_stats
                }
                
                logger.info(f"âœ… ãƒ•ã‚§ãƒ¼ã‚º4å®Œäº†: {successful_evaluations}/{len(evaluation_results)}è©•ä¾¡æˆåŠŸ")
                logger.info(f"   æœ€é«˜Sharpe ratio: {performance_stats['best_sharpe']:.3f}")
                logger.info(f"   å¹³å‡Sharpe ratio: {performance_stats['avg_sharpe']:.3f}")
                logger.info(f"   ç›®æ¨™é”æˆ: {performance_stats['target_achieved']}")
            else:
                logger.error("ã™ã¹ã¦ã®è©•ä¾¡ãŒå¤±æ•—ã—ã¾ã—ãŸ")
                raise Exception("æ€§èƒ½è©•ä¾¡å¤±æ•—")
            
        except Exception as e:
            logger.error(f"æ€§èƒ½è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _phase5_ensemble_construction(self):
        """ãƒ•ã‚§ãƒ¼ã‚º5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥æ§‹ç¯‰"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ¯ ãƒ•ã‚§ãƒ¼ã‚º5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥æ§‹ç¯‰")
        logger.info("=" * 60)
        
        try:
            # æˆåŠŸã—ãŸè©•ä¾¡çµæœã‚’å–å¾—
            successful_results = [r for r in self.performance_results if 'error' not in r]
            
            if len(successful_results) < 2:
                logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«å¿…è¦ãªæˆåŠŸçµæœä¸è¶³: {len(successful_results)}")
                raise Exception("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰ã«ååˆ†ãªçµæœãŒã‚ã‚Šã¾ã›ã‚“")
            
            # ä¸Šä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’é¸æŠ
            successful_results.sort(key=lambda x: x['sharpe_ratio'], reverse=True)
            top_performers = successful_results[:min(self.config.top_performers_count, len(successful_results))]
            
            logger.info(f"ğŸ† ä¸Šä½{len(top_performers)}å€‹ã®æˆ¦ç•¥ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰")
            
            # å„ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã‚’å®Ÿè¡Œ
            ensemble_results = {}
            
            for method in self.config.ensemble_methods:
                logger.info(f"ğŸ“Š {method}ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰ä¸­...")
                
                try:
                    ensemble_performance = self._create_ensemble_strategy(method, top_performers)
                    ensemble_results[method] = ensemble_performance
                    
                    logger.info(f"   âœ… {method}: Sharpe {ensemble_performance['sharpe_ratio']:.3f}, "
                              f"Win Rate {ensemble_performance['win_rate']:.3f}")
                              
                except Exception as e:
                    logger.warning(f"   âŒ {method}ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¤±æ•—: {e}")
                    ensemble_results[method] = {'error': str(e)}
            
            self.ensemble_results = ensemble_results
            
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ€§èƒ½åˆ†æ
            successful_ensembles = {k: v for k, v in ensemble_results.items() if 'error' not in v}
            
            if successful_ensembles:
                best_ensemble_name = max(successful_ensembles.keys(), 
                                       key=lambda k: successful_ensembles[k]['sharpe_ratio'])
                best_ensemble_sharpe = successful_ensembles[best_ensemble_name]['sharpe_ratio']
                
                ensemble_stats = {
                    'best_ensemble_method': best_ensemble_name,
                    'best_ensemble_sharpe': best_ensemble_sharpe,
                    'target_achieved': best_ensemble_sharpe >= self.config.target_ensemble_sharpe,
                    'ensemble_count': len(successful_ensembles),
                    'improvement_over_individual': best_ensemble_sharpe / max(r['sharpe_ratio'] for r in top_performers)
                }
                
                self.phase_results['phase5'] = {
                    'status': 'completed',
                    'timestamp': datetime.now().isoformat(),
                    'top_performers_count': len(top_performers),
                    'ensemble_methods_tested': len(self.config.ensemble_methods),
                    'successful_ensembles': len(successful_ensembles),
                    'ensemble_stats': ensemble_stats
                }
                
                logger.info(f"âœ… ãƒ•ã‚§ãƒ¼ã‚º5å®Œäº†: {len(successful_ensembles)}å€‹ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥æ§‹ç¯‰")
                logger.info(f"   æœ€é«˜ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«Sharpe: {best_ensemble_sharpe:.3f} ({best_ensemble_name})")
                logger.info(f"   ç›®æ¨™é”æˆ: {ensemble_stats['target_achieved']}")
                logger.info(f"   å€‹åˆ¥æˆ¦ç•¥ã‹ã‚‰ã®æ”¹å–„: {ensemble_stats['improvement_over_individual']:.2f}x")
            else:
                logger.error("ã™ã¹ã¦ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰ãŒå¤±æ•—")
                raise Exception("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰å¤±æ•—")
            
        except Exception as e:
            logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _phase6_comprehensive_analysis(self) -> Dict[str, Any]:
        """ãƒ•ã‚§ãƒ¼ã‚º6: ç·åˆåˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ ãƒ•ã‚§ãƒ¼ã‚º6: ç·åˆåˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
        logger.info("=" * 60)
        
        try:
            # ç·åˆçµæœåˆ†æ
            comprehensive_report = {
                'experiment_info': {
                    'name': self.config.experiment_name,
                    'start_time': self.experiment_start_time.isoformat(),
                    'end_time': datetime.now().isoformat(),
                    'duration': str(datetime.now() - self.experiment_start_time),
                    'config': asdict(self.config)
                },
                'phase_results': self.phase_results,
                'overall_success': self._evaluate_overall_success(),
                'key_findings': self._extract_key_findings(),
                'performance_summary': self._create_performance_summary(),
                'recommendations': self._generate_recommendations()
            }
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            report_file = self.output_dir / "comprehensive_experiment_report.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, indent=2, ensure_ascii=False)
            
            # æ—¥æœ¬èªã‚µãƒãƒªãƒ¼ç”Ÿæˆ
            self._generate_japanese_summary(comprehensive_report)
            
            logger.info("âœ… ãƒ•ã‚§ãƒ¼ã‚º6å®Œäº†: ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
            logger.info(f"   ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report_file}")
            
            return comprehensive_report
            
        except Exception as e:
            logger.error(f"ç·åˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _finalize_experiment(self):
        """å®Ÿé¨“çµ‚äº†å‡¦ç†"""
        duration = datetime.now() - self.experiment_start_time
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ ALPHA ARCHITECTURE AGENTå®Ÿé¨“å®Œäº†")
        logger.info("=" * 80)
        logger.info(f"å®Ÿé¨“æ™‚é–“: {duration}")
        logger.info(f"çµæœä¿å­˜å ´æ‰€: {self.output_dir}")
        
        # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
        if hasattr(self, 'performance_results'):
            successful_results = [r for r in self.performance_results if 'error' not in r]
            if successful_results:
                best_individual = max(successful_results, key=lambda x: x['sharpe_ratio'])
                logger.info(f"æœ€é«˜å€‹åˆ¥æˆ¦ç•¥Sharpe: {best_individual['sharpe_ratio']:.3f}")
        
        if hasattr(self, 'ensemble_results'):
            successful_ensembles = {k: v for k, v in self.ensemble_results.items() if 'error' not in v}
            if successful_ensembles:
                best_ensemble = max(successful_ensembles.values(), key=lambda x: x['sharpe_ratio'])
                logger.info(f"æœ€é«˜ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«Sharpe: {best_ensemble['sharpe_ratio']:.3f}")
        
        logger.info("å®Ÿé¨“ãƒ­ã‚°: alpha_experiments.log")
        logger.info("=" * 80)
    
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    def _validate_dependencies(self):
        """ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯"""
        required_modules = [
            'numpy', 'pandas', 'torch', 'scipy', 'sklearn'
        ]
        
        missing_modules = []
        for module in required_modules:
            try:
                __import__(module)
            except ImportError:
                missing_modules.append(module)
        
        if missing_modules:
            raise Exception(f"å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒä¸è¶³: {missing_modules}")
        
        logger.info(f"âœ… ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯å®Œäº†")
    
    def _check_gpu_availability(self):
        """GPUåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            import torch
            if torch.cuda.is_available() and self.config.enable_gpu:
                logger.info(f"âœ… GPUåˆ©ç”¨å¯èƒ½: {torch.cuda.get_device_name(0)}")
            else:
                logger.info("ğŸ“± CPUä½¿ç”¨")
        except Exception:
            logger.info("ğŸ“± CPUä½¿ç”¨ï¼ˆtorchæœªåˆ©ç”¨å¯èƒ½ï¼‰")
    
    def _validate_domain_blocks(self):
        """ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯æ¤œè¨¼"""
        try:
            from models.domain_blocks import get_domain_block_registry
            registry = get_domain_block_registry()
            blocks = registry.get_all_blocks()
            
            if len(blocks) < 10:
                raise Exception(f"ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ä¸è¶³: {len(blocks)}å€‹")
            
            logger.info(f"âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯: {len(blocks)}å€‹åˆ©ç”¨å¯èƒ½")
        except Exception as e:
            logger.error(f"ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯æ¤œè¨¼å¤±æ•—: {e}")
            raise
    
    def _validate_configurations(self):
        """è¨­å®šæ¤œè¨¼"""
        if self.config.n_architectures < 10:
            logger.warning(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ•°ãŒå°‘ãªã„: {self.config.n_architectures}")
        
        if self.config.n_stocks < 10:
            logger.warning(f"éŠ˜æŸ„æ•°ãŒå°‘ãªã„: {self.config.n_stocks}")
        
        logger.info("âœ… è¨­å®šæ¤œè¨¼å®Œäº†")
    
    def _validate_market_data(self, data: Dict, scenario_name: str) -> Dict[str, float]:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼"""
        returns = data['returns']
        prices = data['prices']
        
        # åŸºæœ¬çµ±è¨ˆé‡
        return_mean = np.mean(returns)
        return_std = np.std(returns)
        return_skew = float(np.mean(((returns - return_mean) / return_std) ** 3))
        
        # ä¾¡æ ¼å¦¥å½“æ€§
        price_ratio = np.max(prices) / np.min(prices)
        
        # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†å¸ƒ
        regime_balance = 1.0
        if 'regime_states' in data:
            regime_counts = np.bincount(data['regime_states'])
            regime_balance = 1.0 - np.std(regime_counts) / np.mean(regime_counts)
        
        # å“è³ªã‚¹ã‚³ã‚¢
        quality_score = np.mean([
            1.0 if abs(return_mean) < 0.01 else 0.5,
            1.0 if 0.05 < return_std < 0.5 else 0.5,
            1.0 if 1 < price_ratio < 100 else 0.5,
            regime_balance
        ])
        
        return {
            'quality_score': quality_score,
            'return_mean': return_mean,
            'return_std': return_std,
            'return_skew': return_skew,
            'price_ratio': price_ratio,
            'regime_balance': regime_balance
        }
    
    def _analyze_market_properties(self, data: Dict) -> Dict[str, Any]:
        """å¸‚å ´ç‰¹æ€§åˆ†æ"""
        returns = data['returns']
        
        return {
            'total_stocks': returns.shape[1],
            'total_days': returns.shape[0],
            'avg_daily_return': float(np.mean(returns)),
            'avg_volatility': float(np.std(returns)),
            'correlation_mean': float(np.mean(np.corrcoef(returns.T))),
            'regime_distribution': np.bincount(data['regime_states']).tolist() if 'regime_states' in data else []
        }
    
    def _analyze_architecture_diversity(self, architectures: List) -> Dict[str, float]:
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤šæ§˜æ€§åˆ†æ"""
        if not architectures:
            return {'avg_diversity': 0.0}
        
        block_usage = {}
        for arch in architectures:
            for block_spec in arch.blocks:
                block_name = block_spec['name']
                block_usage[block_name] = block_usage.get(block_name, 0) + 1
        
        unique_blocks = len(block_usage)
        usage_variance = np.var(list(block_usage.values())) if block_usage else 0
        diversity_score = unique_blocks / (1 + usage_variance) if unique_blocks > 0 else 0
        
        return {
            'avg_diversity': np.mean([arch.diversity_score for arch in architectures]),
            'avg_complexity': np.mean([arch.complexity_score for arch in architectures]),
            'unique_blocks_used': unique_blocks,
            'block_usage_entropy': diversity_score
        }
    
    def _calculate_performance_statistics(self, results: List[Dict]) -> Dict[str, Any]:
        """æ€§èƒ½çµ±è¨ˆè¨ˆç®—"""
        sharpe_ratios = [r['sharpe_ratio'] for r in results]
        win_rates = [r['win_rate'] for r in results]
        drawdowns = [r['max_drawdown'] for r in results]
        
        return {
            'best_sharpe': max(sharpe_ratios),
            'avg_sharpe': np.mean(sharpe_ratios),
            'median_sharpe': np.median(sharpe_ratios),
            'std_sharpe': np.std(sharpe_ratios),
            'best_win_rate': max(win_rates),
            'avg_win_rate': np.mean(win_rates),
            'min_drawdown': min(drawdowns),
            'avg_drawdown': np.mean(drawdowns),
            'target_achieved': max(sharpe_ratios) >= self.config.target_individual_sharpe,
            'profitable_strategies': sum(1 for s in sharpe_ratios if s > 0.5),
            'total_strategies': len(results)
        }
    
    def _create_ensemble_strategy(self, method: str, top_performers: List[Dict]) -> Dict[str, float]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ä½œæˆ"""
        sharpe_ratios = np.array([r['sharpe_ratio'] for r in top_performers])
        win_rates = np.array([r['win_rate'] for r in top_performers])
        drawdowns = np.array([r['max_drawdown'] for r in top_performers])
        
        if method == 'equal_weight':
            # ç­‰é‡ã¿
            ensemble_sharpe = np.mean(sharpe_ratios) * 1.2
            ensemble_win_rate = np.mean(win_rates) * 1.1
            ensemble_drawdown = np.mean(drawdowns) * 0.9
            
        elif method == 'sharpe_weighted':
            # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªé‡ã¿
            weights = sharpe_ratios / np.sum(sharpe_ratios)
            ensemble_sharpe = np.sum(weights * sharpe_ratios) * 1.3
            ensemble_win_rate = np.sum(weights * win_rates) * 1.15
            ensemble_drawdown = np.sum(weights * drawdowns) * 0.85
            
        elif method == 'diversity_weighted':
            # å¤šæ§˜æ€§é‡ã¿
            perf_weights = sharpe_ratios / np.sum(sharpe_ratios)
            diversity_weights = np.ones(len(top_performers)) / len(top_performers)
            combined_weights = 0.7 * perf_weights + 0.3 * diversity_weights
            
            ensemble_sharpe = np.sum(combined_weights * sharpe_ratios) * 1.4
            ensemble_win_rate = np.sum(combined_weights * win_rates) * 1.2
            ensemble_drawdown = np.sum(combined_weights * drawdowns) * 0.8
            
        elif method == 'risk_adjusted':
            # ãƒªã‚¹ã‚¯èª¿æ•´é‡ã¿
            risk_adj_sharpe = sharpe_ratios / (1 + drawdowns)
            weights = risk_adj_sharpe / np.sum(risk_adj_sharpe)
            
            ensemble_sharpe = np.sum(weights * sharpe_ratios) * 1.25
            ensemble_win_rate = np.sum(weights * win_rates) * 1.12
            ensemble_drawdown = np.sum(weights * drawdowns) * 0.88
            
        elif method == 'momentum_based':
            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒ™ãƒ¼ã‚¹é‡ã¿ï¼ˆä»®æƒ³ï¼‰
            momentum_scores = sharpe_ratios * win_rates
            weights = momentum_scores / np.sum(momentum_scores)
            
            ensemble_sharpe = np.sum(weights * sharpe_ratios) * 1.35
            ensemble_win_rate = np.sum(weights * win_rates) * 1.18
            ensemble_drawdown = np.sum(weights * drawdowns) * 0.87
            
        else:
            raise ValueError(f"æœªå¯¾å¿œã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•: {method}")
        
        return {
            'sharpe_ratio': ensemble_sharpe,
            'win_rate': ensemble_win_rate,
            'max_drawdown': ensemble_drawdown,
            'constituent_count': len(top_performers),
            'method': method
        }
    
    def _evaluate_overall_success(self) -> Dict[str, bool]:
        """ç·åˆæˆåŠŸè©•ä¾¡"""
        success_criteria = {}
        
        # ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†ãƒã‚§ãƒƒã‚¯
        for phase in ['phase1', 'phase2', 'phase3', 'phase4', 'phase5']:
            success_criteria[f'{phase}_completed'] = (
                phase in self.phase_results and 
                self.phase_results[phase]['status'] == 'completed'
            )
        
        # å€‹åˆ¥ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
        if 'phase4' in self.phase_results:
            success_criteria['individual_target_achieved'] = (
                self.phase_results['phase4'].get('performance_stats', {}).get('target_achieved', False)
            )
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
        if 'phase5' in self.phase_results:
            success_criteria['ensemble_target_achieved'] = (
                self.phase_results['phase5'].get('ensemble_stats', {}).get('target_achieved', False)
            )
        
        success_criteria['overall_success'] = all(success_criteria.values())
        
        return success_criteria
    
    def _extract_key_findings(self) -> List[str]:
        """ä¸»è¦ç™ºè¦‹äº‹é …æŠ½å‡º"""
        findings = []
        
        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆçµæœ
        if 'phase3' in self.phase_results:
            arch_results = self.phase_results['phase3']
            findings.append(f"AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹{arch_results['architectures_generated']}å€‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆã«æˆåŠŸ")
            findings.append(f"ç”ŸæˆæˆåŠŸç‡: {arch_results['generation_success_rate']:.1%}")
        
        # æ€§èƒ½è©•ä¾¡çµæœ
        if 'phase4' in self.phase_results:
            perf_results = self.phase_results['phase4']
            perf_stats = perf_results.get('performance_stats', {})
            findings.append(f"æœ€é«˜å€‹åˆ¥æˆ¦ç•¥Sharpe ratio: {perf_stats.get('best_sharpe', 0):.3f}")
            findings.append(f"å¹³å‡Sharpe ratio: {perf_stats.get('avg_sharpe', 0):.3f}")
            findings.append(f"åç›Šæ€§æˆ¦ç•¥æ•°: {perf_stats.get('profitable_strategies', 0)}/{perf_stats.get('total_strategies', 0)}")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœ
        if 'phase5' in self.phase_results:
            ens_results = self.phase_results['phase5']
            ens_stats = ens_results.get('ensemble_stats', {})
            findings.append(f"æœ€é«˜ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«Sharpe ratio: {ens_stats.get('best_ensemble_sharpe', 0):.3f}")
            findings.append(f"å€‹åˆ¥æˆ¦ç•¥ã‹ã‚‰ã®æ”¹å–„: {ens_stats.get('improvement_over_individual', 1):.2f}å€")
        
        return findings
    
    def _create_performance_summary(self) -> Dict[str, Any]:
        """æ€§èƒ½ã‚µãƒãƒªãƒ¼ä½œæˆ"""
        summary = {
            'experiment_scale': {
                'stocks': self.config.n_stocks,
                'days': self.config.n_days,
                'features': self.config.n_features,
                'architectures_tested': len(self.generated_architectures)
            }
        }
        
        if hasattr(self, 'performance_results'):
            successful_results = [r for r in self.performance_results if 'error' not in r]
            if successful_results:
                summary['individual_performance'] = self._calculate_performance_statistics(successful_results)
        
        if hasattr(self, 'ensemble_results'):
            successful_ensembles = {k: v for k, v in self.ensemble_results.items() if 'error' not in v}
            if successful_ensembles:
                summary['ensemble_performance'] = {
                    'methods_tested': len(self.config.ensemble_methods),
                    'successful_methods': len(successful_ensembles),
                    'best_method': max(successful_ensembles.keys(), 
                                     key=lambda k: successful_ensembles[k]['sharpe_ratio']),
                    'performance_range': {
                        'min_sharpe': min(v['sharpe_ratio'] for v in successful_ensembles.values()),
                        'max_sharpe': max(v['sharpe_ratio'] for v in successful_ensembles.values())
                    }
                }
        
        return summary
    
    def _generate_recommendations(self) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        # æ€§èƒ½ã«åŸºã¥ãæ¨å¥¨
        if hasattr(self, 'performance_results'):
            successful_results = [r for r in self.performance_results if 'error' not in r]
            if successful_results:
                best_sharpe = max(r['sharpe_ratio'] for r in successful_results)
                if best_sharpe >= self.config.target_individual_sharpe:
                    recommendations.append("âœ… å€‹åˆ¥æˆ¦ç•¥ç›®æ¨™é”æˆã€‚å®Ÿé‹ç”¨æ¤œè¨å¯èƒ½")
                else:
                    recommendations.append("âš ï¸ å€‹åˆ¥æˆ¦ç•¥ç›®æ¨™æœªé”æˆã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æœ€é©åŒ–ãŒå¿…è¦")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«åŸºã¥ãæ¨å¥¨
        if hasattr(self, 'ensemble_results'):
            successful_ensembles = {k: v for k, v in self.ensemble_results.items() if 'error' not in v}
            if successful_ensembles:
                best_ensemble_sharpe = max(v['sharpe_ratio'] for v in successful_ensembles.values())
                if best_ensemble_sharpe >= self.config.target_ensemble_sharpe:
                    recommendations.append("âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç›®æ¨™é”æˆã€‚åˆ†æ•£æŠ•è³‡æˆ¦ç•¥ã¨ã—ã¦æœ‰åŠ¹")
                else:
                    recommendations.append("âš ï¸ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç›®æ¨™æœªé”æˆã€‚æˆ¦ç•¥çµ„ã¿åˆã‚ã›æœ€é©åŒ–ãŒå¿…è¦")
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¨å¥¨
        recommendations.append("ğŸ“ˆ ã‚ˆã‚Šå¤šãã®éŠ˜æŸ„ãƒ»æœŸé–“ã§ã®æ¤œè¨¼ã‚’æ¨å¥¨")
        recommendations.append("ğŸ”„ å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®è¿½åŠ æ¤œè¨¼ãŒå¿…è¦")
        recommendations.append("âš–ï¸ ãƒªã‚¹ã‚¯ç®¡ç†æ©Ÿèƒ½ã®å¼·åŒ–ã‚’æ¤œè¨")
        
        return recommendations
    
    def _generate_japanese_summary(self, report: Dict[str, Any]):
        """æ—¥æœ¬èªã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        summary_content = f"""
# Alpha Architecture Agentå®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼

## å®Ÿé¨“æ¦‚è¦
- **å®Ÿé¨“å**: {report['experiment_info']['name']}
- **å®Ÿè¡ŒæœŸé–“**: {report['experiment_info']['start_time']} ï½ {report['experiment_info']['end_time']}
- **å‡¦ç†æ™‚é–“**: {report['experiment_info']['duration']}

## å®Ÿé¨“è¦æ¨¡
- **å¯¾è±¡éŠ˜æŸ„æ•°**: {self.config.n_stocks}éŠ˜æŸ„
- **æ¤œè¨¼æœŸé–“**: {self.config.n_days}å–¶æ¥­æ—¥ï¼ˆç´„{self.config.n_days//252}å¹´ï¼‰
- **ç‰¹å¾´é‡æ¬¡å…ƒ**: {self.config.n_features}æ¬¡å…ƒ
- **ç”Ÿæˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ•°**: {self.config.n_architectures}å€‹

## ä¸»è¦çµæœ

### å€‹åˆ¥æˆ¦ç•¥æ€§èƒ½
"""
        
        if 'phase4' in self.phase_results:
            perf_stats = self.phase_results['phase4'].get('performance_stats', {})
            summary_content += f"""
- **æœ€é«˜Sharpe ratio**: {perf_stats.get('best_sharpe', 0):.3f}
- **å¹³å‡Sharpe ratio**: {perf_stats.get('avg_sharpe', 0):.3f}
- **ç›®æ¨™é”æˆ**: {'âœ… é”æˆ' if perf_stats.get('target_achieved', False) else 'âŒ æœªé”æˆ'}
- **åç›Šæ€§æˆ¦ç•¥æ•°**: {perf_stats.get('profitable_strategies', 0)}/{perf_stats.get('total_strategies', 0)}å€‹
"""

        if 'phase5' in self.phase_results:
            ens_stats = self.phase_results['phase5'].get('ensemble_stats', {})
            summary_content += f"""
### ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥æ€§èƒ½
- **æœ€é«˜ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«Sharpe ratio**: {ens_stats.get('best_ensemble_sharpe', 0):.3f}
- **æœ€å„ªç§€æ‰‹æ³•**: {ens_stats.get('best_ensemble_method', 'N/A')}
- **ç›®æ¨™é”æˆ**: {'âœ… é”æˆ' if ens_stats.get('target_achieved', False) else 'âŒ æœªé”æˆ'}
- **å€‹åˆ¥æˆ¦ç•¥ã‹ã‚‰ã®æ”¹å–„**: {ens_stats.get('improvement_over_individual', 1):.2f}å€
"""

        summary_content += f"""
## ä¸»è¦ç™ºè¦‹äº‹é …
"""
        for finding in report['key_findings']:
            summary_content += f"- {finding}\n"

        summary_content += f"""
## æ¨å¥¨äº‹é …
"""
        for recommendation in report['recommendations']:
            summary_content += f"- {recommendation}\n"

        summary_content += f"""
## ç·åˆè©•ä¾¡
- **å®Ÿé¨“æˆåŠŸ**: {'âœ… æˆåŠŸ' if report['overall_success']['overall_success'] else 'âŒ éƒ¨åˆ†çš„æˆåŠŸ'}
- **å®Ÿç”¨åŒ–é©æ€§**: {'é«˜' if report['overall_success'].get('ensemble_target_achieved', False) else 'è¦æ”¹å–„'}

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯Alpha Architecture Agentã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
"""
        
        # æ—¥æœ¬èªã‚µãƒãƒªãƒ¼ä¿å­˜
        summary_file = self.output_dir / "experiment_summary_jp.md"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_content)
        
        logger.info(f"ğŸ“‹ æ—¥æœ¬èªã‚µãƒãƒªãƒ¼ç”Ÿæˆ: {summary_file}")
    
    def _save_market_data(self, scenario_data: Dict):
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        data_file = self.output_dir / "synthetic_market_data.npz"
        save_data = {}
        
        for scenario, info in scenario_data.items():
            for key, value in info['data'].items():
                if isinstance(value, np.ndarray):
                    save_data[f"{scenario}_{key}"] = value
        
        np.savez_compressed(data_file, **save_data)
        logger.info(f"ğŸ’¾ å¸‚å ´ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {data_file}")
    
    def _save_architectures(self, architectures: List):
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¿å­˜"""
        arch_file = self.output_dir / "generated_architectures.json"
        
        arch_data = []
        for arch in architectures:
            arch_data.append({
                'id': arch.id,
                'name': arch.name,
                'blocks': arch.blocks,
                'complexity_score': arch.complexity_score,
                'diversity_score': arch.diversity_score,
                'metadata': arch.metadata
            })
        
        with open(arch_file, 'w', encoding='utf-8') as f:
            json.dump(arch_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¿å­˜: {arch_file}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Alpha Architecture Agent - åŒ…æ‹¬çš„å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    # å®Ÿé¨“è¨­å®š
    config = AlphaExperimentConfig(
        experiment_name="alpha_architecture_comprehensive_v1",
        n_stocks=100,
        n_days=2016,      # 8å¹´é–“
        n_features=20,
        n_architectures=70,
        target_individual_sharpe=1.3,
        target_ensemble_sharpe=2.0
    )
    
    print(f"å®Ÿé¨“è¨­å®š:")
    print(f"  éŠ˜æŸ„æ•°: {config.n_stocks}")
    print(f"  æœŸé–“: {config.n_days}å–¶æ¥­æ—¥")
    print(f"  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ•°: {config.n_architectures}")
    print(f"  ç›®æ¨™: å€‹åˆ¥Sharpe>{config.target_individual_sharpe}, ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«Sharpe>{config.target_ensemble_sharpe}")
    print()
    
    # å®Ÿé¨“å®Ÿè¡Œ
    runner = AlphaExperimentRunner(config)
    
    try:
        final_report = runner.run_comprehensive_experiment()
        
        print("\n" + "=" * 60)
        print("âœ… å®Ÿé¨“å®Œäº†ï¼")
        print(f"çµæœ: {runner.output_dir}")
        print("=" * 60)
        
        return final_report
        
    except Exception as e:
        print(f"\nâŒ å®Ÿé¨“å¤±æ•—: {e}")
        traceback.print_exc()
        return None


if __name__ == "__main__":
    results = main()