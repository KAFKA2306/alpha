# セットアップ・デプロイメント

## 概要
Alpha Architecture Agentのセットアップからデプロイメントまでの詳細手順について説明いたします。開発環境、本番環境それぞれの構築方法と運用方法を網羅しております。

## 前提条件

### システム要件
```yaml
最小要件:
  CPU: 4コア以上
  メモリ: 8GB以上
  ストレージ: 50GB以上
  OS: Ubuntu 20.04 LTS / macOS 11+ / Windows 10+
  
推奨要件:
  CPU: 8コア以上
  メモリ: 16GB以上
  ストレージ: 100GB以上（SSD推奨）
  GPU: NVIDIA GPU 4GB以上（オプション）
```

### 必要なソフトウェア
- Python 3.11以上
- Docker & Docker Compose
- Git
- PostgreSQL 13以上（本番環境）
- Redis 6以上
- NVIDIA Docker（GPU使用時）

## 開発環境セットアップ

### 1. リポジトリのクローン

```bash
# リポジトリをクローン
git clone https://github.com/your-org/alpha-architecture-agent.git
cd alpha-architecture-agent

# ブランチ確認
git branch -a
git checkout main
```

### 2. 仮想環境の構築

#### pyenv + pipenv（推奨）
```bash
# pyenvでPython 3.11をインストール
pyenv install 3.11.5
pyenv local 3.11.5

# pipenvで仮想環境を作成
pip install pipenv
pipenv install --dev

# 仮想環境をアクティベート
pipenv shell
```

#### conda環境
```bash
# conda環境の作成
conda create -n alpha-agent python=3.11
conda activate alpha-agent

# 依存関係をインストール
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

#### Dev Container（推奨）
```bash
# VS Codeでプロジェクトを開く
code .

# Dev Containerで開く（.devcontainer/devcontainer.jsonを使用）
# Ctrl+Shift+P -> "Dev Containers: Reopen in Container"
```

### 3. 環境変数の設定

```bash
# .envファイルの作成
cp .env.example .env

# 必要な環境変数を設定
nano .env
```

```.env
# .env
# データベース設定
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=stockprediction
POSTGRES_USER=stock_user
POSTGRES_PASSWORD=stock_pass

# Redis設定
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# API Keys
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
JQUANTS_API_KEY=your_jquants_api_key

# MLflow設定
MLFLOW_TRACKING_URI=http://localhost:5000

# ログレベル
LOG_LEVEL=INFO

# 開発モード
DEBUG=true
```

### 4. データベースのセットアップ

#### Dockerを使用した場合（推奨）
```bash
# Docker Composeでデータベースを起動
docker-compose up -d postgres redis

# データベースの初期化
python scripts/init_database.py

# テストデータの投入
python scripts/load_sample_data.py
```

#### ローカルPostgreSQLを使用する場合
```bash
# PostgreSQLをインストール（Ubuntu）
sudo apt update
sudo apt install postgresql postgresql-contrib

# データベースとユーザーを作成
sudo -u postgres createuser stock_user
sudo -u postgres createdb stockprediction
sudo -u postgres psql -c "ALTER USER stock_user PASSWORD 'stock_pass';"
sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE stockprediction TO stock_user;"

# データベーススキーマの作成
python manage.py migrate
```

### 5. MLflowの設定

```bash
# MLflow追跡サーバーの起動
mlflow server \
  --backend-store-uri postgresql://stock_user:stock_pass@localhost:5432/stockprediction \
  --default-artifact-root ./mlruns \
  --host 0.0.0.0 \
  --port 5000
```

### 6. 開発ツールの設定

#### pre-commitフックの設定
```bash
# pre-commitをインストール
pip install pre-commit

# フックを設定
pre-commit install

# 設定ファイル（.pre-commit-config.yaml）
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: https://github.com/psf/black
    rev: 23.1.0
    hooks:
      - id: black
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.0.1
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
EOF
```

#### VSCode設定
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.sortImports.args": ["--profile", "black"],
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    }
}
```

### 7. 開発環境の動作確認

```bash
# 単体テストの実行
pytest tests/ -v

# コード品質チェック
black --check src/
flake8 src/
mypy src/

# 簡単な動作確認
python examples/demo_architecture_generation.py
```

## 本番環境デプロイメント

### 1. Dockerイメージのビルド

#### Dockerfile
```dockerfile
# Dockerfile
FROM python:3.11-slim

# システム依存関係のインストール
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# 作業ディレクトリの設定
WORKDIR /app

# Python依存関係のインストール
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# アプリケーションコードのコピー
COPY src/ ./src/
COPY config/ ./config/
COPY scripts/ ./scripts/

# 実行ユーザーの作成
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# ヘルスチェック
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
  CMD python scripts/health_check.py

# エントリーポイント
CMD ["python", "-m", "src.api.main"]
```

#### マルチステージビルド
```dockerfile
# Dockerfile.production
FROM python:3.11-slim as builder

# 依存関係のインストール
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# 本番環境イメージ
FROM python:3.11-slim

# システム依存関係
RUN apt-get update && apt-get install -y \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# ユーザー作成
RUN useradd -m -u 1000 appuser

# Pythonパッケージのコピー
COPY --from=builder /root/.local /home/appuser/.local
ENV PATH=/home/appuser/.local/bin:$PATH

# アプリケーションのコピー
WORKDIR /app
COPY --chown=appuser:appuser . .

USER appuser

CMD ["gunicorn", "--bind", "0.0.0.0:8000", "src.api.main:app"]
```

### 2. Docker Composeによるデプロイメント

#### docker-compose.prod.yml
```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.production
    ports:
      - "8000:8000"
    environment:
      - POSTGRES_HOST=postgres
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - postgres
      - redis
      - mlflow
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'

  postgres:
    image: postgres:13
    environment:
      POSTGRES_DB: stockprediction
      POSTGRES_USER: stock_user
      POSTGRES_PASSWORD: stock_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped

  redis:
    image: redis:6-alpine
    volumes:
      - redis_data:/data
    restart: unless-stopped

  mlflow:
    image: mlflow/mlflow:latest
    ports:
      - "5000:5000"
    environment:
      - BACKEND_STORE_URI=postgresql://stock_user:stock_pass@postgres:5432/stockprediction
    depends_on:
      - postgres
    volumes:
      - mlflow_data:/mlflow
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - app
    restart: unless-stopped

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  mlflow_data:
  prometheus_data:
  grafana_data:
```

### 3. Nginx設定

```nginx
# nginx/nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream app {
        server app:8000;
    }

    server {
        listen 80;
        server_name your-domain.com;
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name your-domain.com;

        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;

        location / {
            proxy_pass http://app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        location /api/ {
            proxy_pass http://app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

### 4. Kubernetesデプロイメント

#### デプロイメント設定
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alpha-agent
  labels:
    app: alpha-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: alpha-agent
  template:
    metadata:
      labels:
        app: alpha-agent
    spec:
      containers:
      - name: alpha-agent
        image: your-registry/alpha-agent:latest
        ports:
        - containerPort: 8000
        env:
        - name: POSTGRES_HOST
          value: "postgres-service"
        - name: REDIS_HOST
          value: "redis-service"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: alpha-agent-service
spec:
  selector:
    app: alpha-agent
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
```

#### Helmチャート
```yaml
# helm/values.yaml
replicaCount: 3

image:
  repository: your-registry/alpha-agent
  tag: latest
  pullPolicy: Always

service:
  type: LoadBalancer
  port: 80

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
  hosts:
    - host: api.your-domain.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: alpha-agent-tls
      hosts:
        - api.your-domain.com

resources:
  requests:
    memory: "2Gi"
    cpu: "1000m"
  limits:
    memory: "4Gi"
    cpu: "2000m"

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70

postgresql:
  enabled: true
  auth:
    database: stockprediction
    username: stock_user
    password: stock_pass

redis:
  enabled: true
  auth:
    enabled: false
```

### 5. CI/CDパイプライン

#### GitHub Actions
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run tests
      run: |
        pytest --cov=src tests/
    
    - name: Check code quality
      run: |
        black --check src/
        flake8 src/
        mypy src/

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t ${{ secrets.REGISTRY_URL }}/alpha-agent:${{ github.sha }} .
        docker build -t ${{ secrets.REGISTRY_URL }}/alpha-agent:latest .
    
    - name: Push Docker image
      run: |
        echo ${{ secrets.REGISTRY_PASSWORD }} | docker login ${{ secrets.REGISTRY_URL }} -u ${{ secrets.REGISTRY_USERNAME }} --password-stdin
        docker push ${{ secrets.REGISTRY_URL }}/alpha-agent:${{ github.sha }}
        docker push ${{ secrets.REGISTRY_URL }}/alpha-agent:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to staging
      run: |
        # デプロイスクリプトの実行
        ./scripts/deploy.sh staging ${{ github.sha }}
    
    - name: Run integration tests
      run: |
        ./scripts/integration_tests.sh staging
    
    - name: Deploy to production
      if: success()
      run: |
        ./scripts/deploy.sh production ${{ github.sha }}
```

### 6. 監視・ログ設定

#### Prometheus設定
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'alpha-agent'
    static_configs:
      - targets: ['app:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:9121']
```

#### ログ設定
```python
# src/utils/logging_config.py
import logging
import logging.config
from pythonjsonlogger import jsonlogger

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            '()': jsonlogger.JsonFormatter,
            'format': '%(asctime)s %(name)s %(levelname)s %(message)s'
        },
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'json',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'level': 'INFO',
            'formatter': 'json',
            'filename': '/app/logs/app.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5
        },
    },
    'loggers': {
        '': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False
        }
    }
}

def setup_logging():
    logging.config.dictConfig(LOGGING_CONFIG)
```

### 7. セキュリティ設定

#### SSL/TLS証明書
```bash
# Let's Encryptを使用
sudo apt install certbot
sudo certbot certonly --standalone -d your-domain.com

# 証明書の自動更新
sudo crontab -e
# 以下を追加
0 3 * * * certbot renew --quiet
```

#### ファイアウォール設定
```bash
# UFWの設定
sudo ufw allow ssh
sudo ufw allow 80
sudo ufw allow 443
sudo ufw enable
```

#### APIキーローテーション
```python
# scripts/rotate_api_keys.py
import os
import boto3
from kubernetes import client, config

def rotate_api_keys():
    # 新しいAPIキーの生成
    new_key = generate_new_api_key()
    
    # Kubernetesシークレットの更新
    config.load_incluster_config()
    v1 = client.CoreV1Api()
    
    secret = v1.read_namespaced_secret(
        name='api-keys',
        namespace='default'
    )
    
    secret.data['api_key'] = base64.b64encode(new_key.encode()).decode()
    
    v1.replace_namespaced_secret(
        name='api-keys',
        namespace='default',
        body=secret
    )
    
    # アプリケーションの再起動
    apps_v1 = client.AppsV1Api()
    apps_v1.patch_namespaced_deployment(
        name='alpha-agent',
        namespace='default',
        body={'spec': {'template': {'metadata': {'annotations': {'kubectl.kubernetes.io/restartedAt': datetime.now().isoformat()}}}}}
    )
```

## 運用・保守

### 1. ヘルスチェック

```python
# src/api/health.py
from fastapi import APIRouter, Depends
from src.core.database import get_db_connection
from src.core.cache import get_redis_connection

router = APIRouter()

@router.get("/health")
async def health_check():
    """システムヘルスチェック"""
    checks = {}
    
    # データベース接続確認
    try:
        db = get_db_connection()
        db.execute("SELECT 1")
        checks['database'] = 'healthy'
    except Exception as e:
        checks['database'] = f'unhealthy: {str(e)}'
    
    # Redis接続確認
    try:
        redis = get_redis_connection()
        redis.ping()
        checks['redis'] = 'healthy'
    except Exception as e:
        checks['redis'] = f'unhealthy: {str(e)}'
    
    # 全体ステータス
    overall_status = 'healthy' if all(
        status == 'healthy' for status in checks.values()
    ) else 'unhealthy'
    
    return {
        'status': overall_status,
        'checks': checks,
        'timestamp': datetime.now().isoformat()
    }
```

### 2. バックアップ戦略

```bash
#!/bin/bash
# scripts/backup.sh

# データベースバックアップ
pg_dump -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB > backup_$(date +%Y%m%d_%H%M%S).sql

# ファイルシステムバックアップ
tar -czf data_backup_$(date +%Y%m%d_%H%M%S).tar.gz ./data ./config

# S3へのアップロード
aws s3 cp backup_*.sql s3://your-backup-bucket/database/
aws s3 cp data_backup_*.tar.gz s3://your-backup-bucket/files/

# 古いバックアップの削除（7日以上前）
find . -name "backup_*.sql" -mtime +7 -delete
find . -name "data_backup_*.tar.gz" -mtime +7 -delete
```

### 3. スケーリング

#### 水平スケーリング
```bash
# Kubernetesでのスケーリング
kubectl scale deployment alpha-agent --replicas=5

# オートスケーリングの設定
kubectl autoscale deployment alpha-agent --cpu-percent=70 --min=3 --max=10
```

このセットアップ・デプロイメントガイドに従うことで、Alpha Architecture Agentを安全かつ効率的に運用することができます。