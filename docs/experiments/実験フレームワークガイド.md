# AI エージェント アーキテクチャ検証フレームワーク

## 🎯 概要

本実験フレームワークは、株式予測におけるAIエージェントベースのニューラルネットワークアーキテクチャ生成システムの有効性を検証いたします。日本市場の合成データを用いた包括的な4段階検証手法を実装しております。

## 📁 フレームワーク構成

### コアモジュール

```
src/
├── experiments/
│   └── experiment_runner.py          # メイン実験フレームワーク
├── data/
│   └── synthetic_market.py            # 合成市場データ生成
├── agents/
│   └── architecture_agent.py          # アーキテクチャ生成AIエージェント
└── models/
    ├── domain_blocks.py               # 基本ドメインブロック
    └── domain_blocks_extended.py      # 拡張ドメインブロック
```

### 実験ファイル構成

```
experiments/
├── run_alpha_experiments.py           # フル実験実行
├── run_alpha_experiments_simple.py    # 簡易実験
├── run_alpha_experiments_with_logging.py  # ログ付き実験
├── run_real_data_experiments.py       # 実データ実験
└── experiment_simulation.py           # シミュレーション実験
```

## 🔬 実験手法

### 段階1: 合成データ生成

#### 日本株市場特性の再現
```python
class JapaneseStockMarketSimulator:
    """日本株市場シミュレーター"""
    
    def __init__(self, config):
        self.config = config
        self.market_regimes = ['bull', 'bear', 'sideways']
        self.sector_correlations = self._load_sector_correlations()
    
    def generate_synthetic_data(self, n_stocks=50, n_days=1000):
        """合成市場データの生成
        
        特徴:
        - 現実的なボラティリティクラスタリング
        - セクター間相関の再現
        - 市場レジーム遷移
        - 流動性制約の考慮
        """
        # マクロ経済ファクターの生成
        macro_factors = self._generate_macro_factors(n_days)
        
        # セクターレベルの収益率
        sector_returns = self._generate_sector_returns(macro_factors)
        
        # 個別株の収益率（セクター + 個別要因）
        stock_returns = self._generate_stock_returns(sector_returns, n_stocks)
        
        # 価格データの構築
        price_data = self._returns_to_prices(stock_returns)
        
        return {
            'prices': price_data,
            'returns': stock_returns,
            'macro_factors': macro_factors,
            'sector_data': sector_returns
        }
```

#### データ品質検証
```python
def validate_synthetic_data(data):
    """合成データの品質検証"""
    
    validation_results = {}
    
    # 統計的特性の検証
    returns = data['returns']
    validation_results['mean_return'] = returns.mean().mean()
    validation_results['volatility'] = returns.std().mean()
    validation_results['skewness'] = returns.skew().mean()
    validation_results['kurtosis'] = returns.kurtosis().mean()
    
    # 時系列特性の検証
    validation_results['autocorrelation'] = [
        returns.iloc[:, i].autocorr(lag=1) for i in range(min(10, returns.shape[1]))
    ]
    
    # クラスタリング特性
    validation_results['volatility_clustering'] = check_volatility_clustering(returns)
    
    return validation_results
```

### 段階2: アーキテクチャ生成実験

#### AIエージェント vs ランダム生成比較
```python
class ArchitectureGenerationExperiment:
    """アーキテクチャ生成実験クラス"""
    
    def __init__(self, config):
        self.ai_agent = ArchitectureAgent(config.ai_config)
        self.random_generator = RandomArchitectureGenerator(config.random_config)
        self.config = config
    
    def run_generation_comparison(self):
        """AI エージェント vs ランダム生成の比較実験"""
        
        results = {}
        
        # AIエージェントによる生成
        print("🤖 AIエージェントによるアーキテクチャ生成...")
        ai_architectures = self.ai_agent.generate_architectures(
            input_shape=(self.config.batch_size, self.config.sequence_length, self.config.n_features),
            num_architectures=self.config.num_architectures_per_method
        )
        
        # ランダム生成
        print("🎲 ランダムアーキテクチャ生成...")
        random_architectures = self.random_generator.generate_architectures(
            input_shape=(self.config.batch_size, self.config.sequence_length, self.config.n_features),
            num_architectures=self.config.num_architectures_per_method
        )
        
        # 多様性分析
        results['ai_diversity'] = self._calculate_diversity(ai_architectures)
        results['random_diversity'] = self._calculate_diversity(random_architectures)
        
        # 複雑度分析
        results['ai_complexity'] = self._analyze_complexity(ai_architectures)
        results['random_complexity'] = self._analyze_complexity(random_architectures)
        
        return {
            'ai_architectures': ai_architectures,
            'random_architectures': random_architectures,
            'analysis': results
        }
```

#### アーキテクチャ多様性評価
```python
def calculate_architecture_diversity(architectures):
    """アーキテクチャの多様性を計算"""
    
    # ブロック組み合わせの多様性
    block_combinations = []
    for arch in architectures:
        combination = tuple(sorted([block['type'] for block in arch['blocks']]))
        block_combinations.append(combination)
    
    unique_combinations = len(set(block_combinations))
    diversity_score = unique_combinations / len(architectures)
    
    # 構造的多様性（グラフ編集距離ベース）
    structural_distances = []
    for i in range(len(architectures)):
        for j in range(i+1, len(architectures)):
            distance = calculate_graph_edit_distance(
                architectures[i], architectures[j]
            )
            structural_distances.append(distance)
    
    avg_structural_distance = np.mean(structural_distances)
    
    return {
        'combination_diversity': diversity_score,
        'structural_diversity': avg_structural_distance,
        'unique_patterns': unique_combinations
    }
```

### 段階3: モデル訓練・評価

#### 並列訓練システム
```python
class ParallelTrainingSystem:
    """並列モデル訓練システム"""
    
    def __init__(self, config):
        self.config = config
        self.device_manager = DeviceManager()
        self.training_queue = Queue()
    
    async def train_architectures_parallel(self, architectures, train_data, val_data):
        """複数アーキテクチャの並列訓練"""
        
        # デバイス割り当て
        available_devices = self.device_manager.get_available_devices()
        max_parallel = min(len(available_devices), self.config.max_parallel_training)
        
        # 訓練ジョブの作成
        training_jobs = []
        for i, architecture in enumerate(architectures):
            job = TrainingJob(
                job_id=f"train_{i:03d}",
                architecture=architecture,
                train_data=train_data,
                val_data=val_data,
                config=self.config.training_config
            )
            training_jobs.append(job)
        
        # 並列実行
        results = []
        semaphore = asyncio.Semaphore(max_parallel)
        
        async def train_single_job(job):
            async with semaphore:
                trainer = ModelTrainer(job.config)
                result = await trainer.train_async(
                    job.architecture, job.train_data, job.val_data
                )
                return result
        
        # 全ジョブの並列実行
        tasks = [train_single_job(job) for job in training_jobs]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 結果の整理
        successful_results = [r for r in results if not isinstance(r, Exception)]
        failed_count = len(results) - len(successful_results)
        
        print(f"✅ 訓練完了: {len(successful_results)}/{len(results)} 成功")
        if failed_count > 0:
            print(f"❌ 訓練失敗: {failed_count} ジョブ")
        
        return successful_results
```

#### 性能評価指標
```python
class PerformanceEvaluator:
    """モデル性能評価クラス"""
    
    def __init__(self):
        self.metrics = [
            'accuracy', 'precision', 'recall', 'f1_score',
            'sharpe_ratio', 'information_ratio', 'max_drawdown'
        ]
    
    def evaluate_model_performance(self, model, test_data):
        """モデル性能の包括評価"""
        
        # 予測生成
        predictions = model.predict(test_data.features)
        actual_returns = test_data.returns
        
        # 分類性能（方向性予測）
        direction_pred = np.sign(predictions)
        direction_actual = np.sign(actual_returns)
        
        classification_metrics = {
            'accuracy': accuracy_score(direction_actual, direction_pred),
            'precision': precision_score(direction_actual, direction_pred, average='weighted'),
            'recall': recall_score(direction_actual, direction_pred, average='weighted'),
            'f1_score': f1_score(direction_actual, direction_pred, average='weighted')
        }
        
        # 投資性能
        portfolio_returns = self._calculate_portfolio_returns(
            predictions, actual_returns
        )
        
        investment_metrics = {
            'total_return': (1 + portfolio_returns).prod() - 1,
            'sharpe_ratio': self._calculate_sharpe_ratio(portfolio_returns),
            'information_ratio': self._calculate_information_ratio(portfolio_returns),
            'max_drawdown': self._calculate_max_drawdown(portfolio_returns),
            'calmar_ratio': self._calculate_calmar_ratio(portfolio_returns)
        }
        
        return {
            'classification': classification_metrics,
            'investment': investment_metrics,
            'portfolio_returns': portfolio_returns
        }
```

### 段階4: アンサンブル最適化

#### 相関ベースモデル選択
```python
class EnsembleOptimizer:
    """アンサンブル最適化クラス"""
    
    def __init__(self, correlation_threshold=0.8):
        self.correlation_threshold = correlation_threshold
    
    def optimize_ensemble(self, model_results):
        """最適アンサンブルの構築"""
        
        # 性能順にソート
        sorted_results = sorted(
            model_results, 
            key=lambda x: x['investment']['sharpe_ratio'], 
            reverse=True
        )
        
        # 相関フィルタリング
        selected_models = self._correlation_filter(sorted_results)
        
        # 重み最適化
        optimal_weights = self._optimize_weights(selected_models)
        
        # アンサンブル性能計算
        ensemble_performance = self._calculate_ensemble_performance(
            selected_models, optimal_weights
        )
        
        return {
            'selected_models': selected_models,
            'weights': optimal_weights,
            'performance': ensemble_performance,
            'improvement': self._calculate_improvement(
                sorted_results[0], ensemble_performance
            )
        }
    
    def _correlation_filter(self, model_results):
        """相関に基づくモデルフィルタリング"""
        
        selected_models = [model_results[0]]  # 最高性能モデルを選択
        
        for model in model_results[1:]:
            # 既選択モデルとの相関計算
            correlations = []
            for selected in selected_models:
                corr = np.corrcoef(
                    model['portfolio_returns'],
                    selected['portfolio_returns']
                )[0, 1]
                correlations.append(corr)
            
            # 相関が閾値以下の場合、選択
            if max(correlations) < self.correlation_threshold:
                selected_models.append(model)
                
                # 最大モデル数制限
                if len(selected_models) >= 20:
                    break
        
        return selected_models
```

## 📊 実験実行プロトコル

### 実験設定
```yaml
experiment_config:
  # データ設定
  data:
    n_stocks: 50
    n_days: 1000
    train_ratio: 0.6
    val_ratio: 0.2
    test_ratio: 0.2
  
  # アーキテクチャ生成
  architecture_generation:
    num_ai_architectures: 35
    num_random_architectures: 35
    total_architectures: 70
    complexity_range: [5, 20]
  
  # 訓練設定
  training:
    epochs: 100
    batch_size: 32
    learning_rate: 0.001
    early_stopping_patience: 10
    max_parallel_jobs: 4
  
  # 評価設定
  evaluation:
    correlation_threshold: 0.8
    top_n_ensemble: 20
    benchmark: "equal_weight"
```

### 実験実行手順

#### ステップ1: 環境準備
```bash
# 実験環境の準備
python -m venv experiment_env
source experiment_env/bin/activate
pip install -r requirements.txt

# 設定ファイルの確認
python -c "from src.core.config import Config; Config.validate_experiment_config()"
```

#### ステップ2: データ生成・検証
```bash
# 合成データの生成
python experiments/generate_synthetic_data.py --config config/experiment_config.yaml

# データ品質の検証
python experiments/validate_data_quality.py --data_path data/synthetic/
```

#### ステップ3: アーキテクチャ生成実験
```bash
# アーキテクチャ生成実験の実行
python experiments/run_architecture_generation.py \
  --ai_architectures 35 \
  --random_architectures 35 \
  --output_path results/architectures/
```

#### ステップ4: 並列訓練実行
```bash
# 並列モデル訓練
python experiments/run_parallel_training.py \
  --architectures_path results/architectures/ \
  --data_path data/synthetic/ \
  --max_parallel 4 \
  --output_path results/models/
```

#### ステップ5: アンサンブル最適化
```bash
# アンサンブル最適化
python experiments/run_ensemble_optimization.py \
  --models_path results/models/ \
  --correlation_threshold 0.8 \
  --top_n 20 \
  --output_path results/ensemble/
```

## 📈 期待される結果

### 性能目標
```yaml
target_metrics:
  individual_models:
    best_sharpe_ratio: "> 1.0"
    average_sharpe_ratio: "> 0.5"
    hit_rate: "> 0.55"
  
  ensemble:
    sharpe_ratio: "> 2.0"
    max_drawdown: "< 0.15"
    information_ratio: "> 1.5"
  
  generation_quality:
    ai_vs_random_improvement: "> 15%"
    diversity_score: "> 0.7"
    unique_patterns: "> 20"
```

### 検証項目
1. **AIエージェント有効性**: ランダム生成に対する優位性
2. **アンサンブル効果**: 個別モデルに対する性能向上
3. **多様性確保**: 相関の低い高性能モデル群の生成
4. **スケーラビリティ**: 大規模実験での安定動作

## 🔧 実験監視・デバッグ

### リアルタイム監視
```python
class ExperimentMonitor:
    """実験監視クラス"""
    
    def __init__(self, config):
        self.config = config
        self.metrics_logger = MetricsLogger()
        self.alert_manager = AlertManager()
    
    def monitor_training_progress(self, training_jobs):
        """訓練進捗の監視"""
        
        while True:
            # 各ジョブの状況確認
            for job in training_jobs:
                status = job.get_status()
                
                # メトリクス記録
                self.metrics_logger.log_training_metrics(
                    job_id=job.id,
                    epoch=status.current_epoch,
                    train_loss=status.train_loss,
                    val_loss=status.val_loss,
                    gpu_usage=status.gpu_usage
                )
                
                # 異常検知
                if status.train_loss > 10.0:  # 発散検知
                    self.alert_manager.send_alert(
                        f"Training divergence detected: Job {job.id}"
                    )
                
                if status.gpu_usage > 95:  # GPU使用率警告
                    self.alert_manager.send_alert(
                        f"High GPU usage: Job {job.id} ({status.gpu_usage}%)"
                    )
            
            time.sleep(30)  # 30秒間隔で監視
```

### デバッグ支援
```python
class ExperimentDebugger:
    """実験デバッグ支援クラス"""
    
    def diagnose_training_failure(self, failed_job):
        """訓練失敗の診断"""
        
        diagnosis = {}
        
        # ログ分析
        logs = failed_job.get_logs()
        diagnosis['error_messages'] = self._extract_error_messages(logs)
        
        # アーキテクチャ分析
        arch = failed_job.architecture
        diagnosis['architecture_issues'] = self._check_architecture_validity(arch)
        
        # データ分析
        data = failed_job.data
        diagnosis['data_issues'] = self._check_data_quality(data)
        
        # リソース分析
        diagnosis['resource_issues'] = self._check_resource_usage(failed_job)
        
        return diagnosis
```

## 📋 実験レポート自動生成

### 結果集約・分析
```python
class ExperimentReporter:
    """実験レポート生成クラス"""
    
    def generate_comprehensive_report(self, experiment_results):
        """包括的実験レポートの生成"""
        
        report = {
            'experiment_summary': self._generate_summary(experiment_results),
            'architecture_analysis': self._analyze_architectures(experiment_results),
            'performance_analysis': self._analyze_performance(experiment_results),
            'ensemble_analysis': self._analyze_ensemble(experiment_results),
            'conclusions': self._draw_conclusions(experiment_results),
            'recommendations': self._generate_recommendations(experiment_results)
        }
        
        # Markdown レポート生成
        markdown_report = self._format_as_markdown(report)
        
        # 図表生成
        charts = self._generate_charts(experiment_results)
        
        return {
            'report': markdown_report,
            'charts': charts,
            'raw_data': experiment_results
        }
```

この実験フレームワークにより、AIエージェントベースのアーキテクチャ生成システムの有効性を科学的かつ包括的に検証することができます。