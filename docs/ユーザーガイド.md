# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦
Alpha Architecture Agentã®ä½¿ç”¨æ–¹æ³•ã«ã¤ã„ã¦ã€åˆå¿ƒè€…ã‹ã‚‰ä¸Šç´šè€…ã¾ã§æ®µéšçš„ã«èª¬æ˜ã„ãŸã—ã¾ã™ã€‚æœ¬ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬æ“ä½œã‹ã‚‰é«˜åº¦ãªå®Ÿé¨“è¨­å®šã¾ã§ã€å®Ÿç”¨çš„ãªä¾‹ã‚’äº¤ãˆã¦è§£èª¬ã—ã¦ãŠã‚Šã¾ã™ã€‚

## ç›®æ¬¡
1. [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
2. [åŸºæœ¬æ“ä½œ](#åŸºæœ¬æ“ä½œ)
3. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ)
4. [ãƒ¢ãƒ‡ãƒ«è¨“ç·´](#ãƒ¢ãƒ‡ãƒ«è¨“ç·´)
5. [ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ](#ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ)
6. [çµæœåˆ†æ](#çµæœåˆ†æ)
7. [é«˜åº¦ãªä½¿ç”¨æ³•](#é«˜åº¦ãªä½¿ç”¨æ³•)
8. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 5åˆ†ã§å§‹ã‚ã‚‹ Alpha Architecture Agent

#### ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒç¢ºèª
```bash
# Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç¢ºèª
python --version  # 3.11ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª
pip list | grep -E "(torch|pandas|numpy)"
```

#### ã‚¹ãƒ†ãƒƒãƒ—2: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™
```bash
# ã‚µãƒ³ãƒ—ãƒ«è¨­å®šã‚’ã‚³ãƒ”ãƒ¼
cp config/config.yaml.example config/config.yaml

# æœ€å°é™ã®è¨­å®šã‚’ç¢ºèª
cat config/config.yaml
```

#### ã‚¹ãƒ†ãƒƒãƒ—3: ç°¡å˜ãªãƒ‡ãƒ¢å®Ÿè¡Œ
```bash
# ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ
python examples/demo_architecture_generation.py

# çµæœç¢ºèª
ls results/
```

#### ã‚¹ãƒ†ãƒƒãƒ—4: Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®èµ·å‹•
```bash
# APIã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•
uvicorn src.api.main:app --reload

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹
# http://localhost:8000/docs
```

ã“ã‚Œã§åŸºæœ¬çš„ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã€Alpha Architecture Agentã‚’ä½¿ã„å§‹ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

## åŸºæœ¬æ“ä½œ

### 1. ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

#### åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰
```bash
# ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
python -m src.cli --help

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ç¢ºèª
python -m src.cli status

# è¨­å®šç¢ºèª
python -m src.cli config show
```

#### ãƒ‡ãƒ¼ã‚¿åé›†
```bash
# æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ã®åé›†
python -m src.cli data collect \
  --symbols "7203.T,9984.T,6758.T" \
  --start-date "2023-01-01" \
  --end-date "2024-06-30"

# åé›†çŠ¶æ³ã®ç¢ºèª
python -m src.cli data status
```

### 2. Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã®åŸºæœ¬ä½¿ç”¨

#### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹
```python
from src.agents.architecture_agent import ArchitectureAgent
from src.core.config import Config

# è¨­å®šã®èª­ã¿è¾¼ã¿
config = Config.from_yaml('config/config.yaml')

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
agent = ArchitectureAgent(config)

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç”Ÿæˆ
architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=10
)

print(f"ç”Ÿæˆã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ•°: {len(architectures)}")
for i, arch in enumerate(architectures):
    print(f"{i+1}. {arch['name']}: è¤‡é›‘åº¦ {arch['complexity']}")
```

### 3. Jupyter Notebookã§ã®ä½¿ç”¨

#### Notebookã®èµ·å‹•
```bash
# Jupyter Notebookã®èµ·å‹•
jupyter notebook notebooks/

# ã¾ãŸã¯ Jupyter Lab
jupyter lab notebooks/
```

#### åŸºæœ¬çš„ãªNotebookä¾‹
```python
# notebooks/getting_started.ipynb

# ã‚»ãƒ«1: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.agents.architecture_agent import ArchitectureAgent
from src.core.config import Config

# ã‚»ãƒ«2: è¨­å®šã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
config = Config.from_yaml('../config/config.yaml')
agent = ArchitectureAgent(config)

# ã‚»ãƒ«3: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ
architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=5
)

# ã‚»ãƒ«4: çµæœã®å¯è¦–åŒ–
complexity_scores = [arch['complexity'] for arch in architectures]
plt.figure(figsize=(10, 6))
plt.bar(range(len(complexity_scores)), complexity_scores)
plt.xlabel('ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ID')
plt.ylabel('è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢')
plt.title('ç”Ÿæˆã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¤‡é›‘åº¦åˆ†å¸ƒ')
plt.show()
```

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ

### 1. AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ç”Ÿæˆ

#### åŸºæœ¬çš„ãªç”Ÿæˆ
```python
from src.agents.architecture_agent import ArchitectureAgent

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
agent = ArchitectureAgent(config)

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ
architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),  # (ãƒãƒƒãƒ, ç³»åˆ—é•·, ç‰¹å¾´æ•°)
    num_architectures=50,
    generation_mode='ai_agent'
)

# ç”Ÿæˆçµæœã®ç¢ºèª
for arch in architectures[:5]:  # ä¸Šä½5ã¤ã‚’è¡¨ç¤º
    print(f"åå‰: {arch['name']}")
    print(f"ãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(arch['blocks'])}")
    print(f"è¤‡é›‘åº¦: {arch['complexity']}")
    print("---")
```

#### ã‚«ã‚¹ã‚¿ãƒ åˆ¶ç´„ã§ã®ç”Ÿæˆ
```python
# åˆ¶ç´„æ¡ä»¶ã‚’æŒ‡å®š
constraints = {
    'max_complexity': 15,
    'min_complexity': 5,
    'required_blocks': ['PCABlock', 'LSTMBlock'],
    'forbidden_blocks': ['TransformerBlock'],
    'max_parameters': 1000000
}

# åˆ¶ç´„ä»˜ãç”Ÿæˆ
constrained_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=30,
    constraints=constraints
)
```

### 2. ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆã¨ã®æ¯”è¼ƒ

```python
# AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”Ÿæˆ
ai_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=25,
    generation_mode='ai_agent'
)

# ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆ
random_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=25,
    generation_mode='random'
)

# å¤šæ§˜æ€§ã®æ¯”è¼ƒ
from src.utils.diversity import calculate_diversity

ai_diversity = calculate_diversity(ai_architectures)
random_diversity = calculate_diversity(random_architectures)

print(f"AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¤šæ§˜æ€§: {ai_diversity:.3f}")
print(f"ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆå¤šæ§˜æ€§: {random_diversity:.3f}")
```

### 3. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç”Ÿæˆ

```python
# AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ©ãƒ³ãƒ€ãƒ ã®çµ„ã¿åˆã‚ã›
hybrid_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=50,
    generation_mode='hybrid',
    ai_ratio=0.7  # 70%ã‚’AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€30%ã‚’ãƒ©ãƒ³ãƒ€ãƒ 
)
```

## ãƒ¢ãƒ‡ãƒ«è¨“ç·´

### 1. å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

#### åŸºæœ¬çš„ãªè¨“ç·´
```python
from src.training.model_trainer import ModelTrainer
from src.data.data_loader import DataLoader

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
data_loader = DataLoader(config.data_config)
train_data, val_data, test_data = data_loader.load_and_split_data()

# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
trainer = ModelTrainer(config.training_config)

# å˜ä¸€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨“ç·´
architecture = architectures[0]  # æœ€åˆã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨
model = trainer.train_model(
    architecture=architecture,
    train_data=train_data,
    val_data=val_data
)

print(f"è¨“ç·´å®Œäº†: {model['name']}")
print(f"æœ€çµ‚æ¤œè¨¼æå¤±: {model['val_loss']:.4f}")
```

#### è©³ç´°ãªè¨“ç·´è¨­å®š
```python
# ã‚«ã‚¹ã‚¿ãƒ è¨“ç·´è¨­å®š
training_config = {
    'epochs': 150,
    'batch_size': 64,
    'learning_rate': 0.0005,
    'weight_decay': 0.0001,
    'scheduler': 'cosine',
    'early_stopping': {
        'enabled': True,
        'patience': 15,
        'min_delta': 0.0001
    },
    'data_augmentation': {
        'noise_std': 0.01,
        'dropout_rate': 0.1
    }
}

# è©³ç´°è¨­å®šã§ã®è¨“ç·´
detailed_trainer = ModelTrainer(training_config)
model = detailed_trainer.train_model(architecture, train_data, val_data)
```

### 2. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸¦åˆ—è¨“ç·´

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def train_multiple_models(architectures, data):
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸¦åˆ—è¨“ç·´"""
    
    def train_single_model(architecture):
        trainer = ModelTrainer(config.training_config)
        return trainer.train_model(architecture, data['train'], data['val'])
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [
            executor.submit(train_single_model, arch) 
            for arch in architectures
        ]
        
        models = []
        for i, future in enumerate(futures):
            try:
                model = future.result()
                models.append(model)
                print(f"ãƒ¢ãƒ‡ãƒ« {i+1}/{len(architectures)} å®Œäº†")
            except Exception as e:
                print(f"ãƒ¢ãƒ‡ãƒ« {i+1} è¨“ç·´å¤±æ•—: {e}")
                models.append(None)
    
    return [m for m in models if m is not None]

# å®Ÿè¡Œ
models = await train_multiple_models(architectures[:10], {
    'train': train_data,
    'val': val_data
})
```

### 3. è¨“ç·´ç›£è¦–ã¨ãƒ­ã‚°

```python
# MLflowã¨ã®çµ±åˆ
import mlflow
import mlflow.pytorch

class MLflowTrainer(ModelTrainer):
    def train_model(self, architecture, train_data, val_data):
        with mlflow.start_run():
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²
            mlflow.log_params({
                'architecture_name': architecture['name'],
                'num_blocks': len(architecture['blocks']),
                'complexity': architecture['complexity']
            })
            
            # è¨“ç·´å®Ÿè¡Œ
            model = super().train_model(architecture, train_data, val_data)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
            mlflow.log_metrics({
                'final_train_loss': model['train_loss'],
                'final_val_loss': model['val_loss'],
                'training_time': model['training_time']
            })
            
            # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
            mlflow.pytorch.log_model(model['pytorch_model'], "model")
            
            return model

# MLflowçµ±åˆè¨“ç·´ã®å®Ÿè¡Œ
mlflow_trainer = MLflowTrainer(config.training_config)
models = [mlflow_trainer.train_model(arch, train_data, val_data) for arch in architectures[:5]]
```

## ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

### 1. åŸºæœ¬çš„ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

```python
from src.backtesting.backtester import Backtester

# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®š
backtest_config = {
    'start_date': '2023-01-01',
    'end_date': '2024-06-30',
    'initial_capital': 10000000,  # 1000ä¸‡å††
    'long_percentage': 0.05,      # ä¸Šä½5%ã‚’ãƒ­ãƒ³ã‚°
    'short_percentage': 0.05,     # ä¸‹ä½5%ã‚’ã‚·ãƒ§ãƒ¼ãƒˆ
    'rebalance_frequency': 'daily',
    'transaction_cost': 0.001     # 0.1%ã®å–å¼•ã‚³ã‚¹ãƒˆ
}

# ãƒãƒƒã‚¯ãƒ†ã‚¹ã‚¿ãƒ¼ã®åˆæœŸåŒ–
backtester = Backtester(backtest_config)

# å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
model = models[0]
result = backtester.run_backtest(model, test_data)

print(f"ç·åç›Šç‡: {result['total_return']:.2%}")
print(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {result['sharpe_ratio']:.2f}")
print(f"æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {result['max_drawdown']:.2%}")
```

### 2. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

```python
# å…¨ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
results = []
for i, model in enumerate(models):
    result = backtester.run_backtest(model, test_data)
    result['model_id'] = i
    result['model_name'] = model['name']
    results.append(result)

# çµæœã®æ¯”è¼ƒ
import pandas as pd

comparison_df = pd.DataFrame([
    {
        'ãƒ¢ãƒ‡ãƒ«å': r['model_name'],
        'ç·åç›Šç‡': f"{r['total_return']:.2%}",
        'ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª': f"{r['sharpe_ratio']:.2f}",
        'æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³': f"{r['max_drawdown']:.2%}",
        'ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª': f"{r['calmar_ratio']:.2f}"
    }
    for r in results
])

print(comparison_df.sort_values('ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª', ascending=False))
```

### 3. é«˜åº¦ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®š

```python
# ãƒªã‚¹ã‚¯ç®¡ç†ä»˜ããƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
advanced_config = {
    'start_date': '2023-01-01',
    'end_date': '2024-06-30',
    'initial_capital': 10000000,
    'position_sizing': {
        'method': 'risk_parity',
        'target_volatility': 0.15,
        'max_position_size': 0.02,
        'sector_limit': 0.3
    },
    'risk_management': {
        'stop_loss': 0.05,
        'take_profit': 0.15,
        'max_drawdown_limit': 0.1
    },
    'transaction_costs': {
        'commission_rate': 0.001,
        'market_impact': 0.0005,
        'bid_ask_spread': 0.0002
    }
}

advanced_backtester = Backtester(advanced_config)
advanced_result = advanced_backtester.run_backtest(model, test_data)
```

## çµæœåˆ†æ

### 1. æ€§èƒ½åˆ†æ

```python
from src.analysis.performance_analyzer import PerformanceAnalyzer

# åˆ†æå™¨ã®åˆæœŸåŒ–
analyzer = PerformanceAnalyzer()

# è©³ç´°åˆ†æã®å®Ÿè¡Œ
analysis = analyzer.analyze_performance(results)

# çµ±è¨ˆã‚µãƒãƒªãƒ¼
print("=== æ€§èƒ½çµ±è¨ˆ ===")
print(f"å¹³å‡ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {analysis['mean_sharpe']:.2f}")
print(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæ¨™æº–åå·®: {analysis['std_sharpe']:.2f}")
print(f"æœ€é«˜ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {analysis['max_sharpe']:.2f}")
print(f"å‹ç‡: {analysis['win_rate']:.1%}")
```

### 2. è¦–è¦šåŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns

# æ€§èƒ½åˆ†å¸ƒã®å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã®åˆ†å¸ƒ
axes[0, 0].hist([r['sharpe_ratio'] for r in results], bins=20, alpha=0.7)
axes[0, 0].set_title('ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã®åˆ†å¸ƒ')
axes[0, 0].set_xlabel('ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª')
axes[0, 0].set_ylabel('é »åº¦')

# åç›Šç‡vsæœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
axes[0, 1].scatter(
    [r['max_drawdown'] for r in results],
    [r['total_return'] for r in results],
    alpha=0.7
)
axes[0, 1].set_title('åç›Šç‡ vs æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³')
axes[0, 1].set_xlabel('æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³')
axes[0, 1].set_ylabel('ç·åç›Šç‡')

# è¤‡é›‘åº¦vsæ€§èƒ½
complexities = [arch['complexity'] for arch in architectures]
sharpe_ratios = [r['sharpe_ratio'] for r in results]

axes[1, 0].scatter(complexities, sharpe_ratios, alpha=0.7)
axes[1, 0].set_title('ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¤‡é›‘åº¦ vs ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª')
axes[1, 0].set_xlabel('è¤‡é›‘åº¦')
axes[1, 0].set_ylabel('ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª')

# ç´¯ç©åç›Šã®æ™‚ç³»åˆ—
best_result = max(results, key=lambda x: x['sharpe_ratio'])
cumulative_returns = (1 + best_result['daily_returns']).cumprod()

axes[1, 1].plot(cumulative_returns.index, cumulative_returns.values)
axes[1, 1].set_title('æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®ç´¯ç©åç›Š')
axes[1, 1].set_xlabel('æ—¥ä»˜')
axes[1, 1].set_ylabel('ç´¯ç©åç›Š')

plt.tight_layout()
plt.show()
```

### 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†æ

```python
from src.ensemble.ensemble_manager import EnsembleManager

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
ensemble_manager = EnsembleManager()

# ä¸Šä½20ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
top_models = ensemble_manager.select_top_models(
    results=results,
    models=models,
    top_n=20,
    selection_criteria='sharpe_ratio',
    correlation_threshold=0.8
)

print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¯¾è±¡ãƒ¢ãƒ‡ãƒ«æ•°: {len(top_models)}")

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
ensemble_result = backtester.run_ensemble_backtest(top_models, test_data)

print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {ensemble_result['sharpe_ratio']:.2f}")
print(f"å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«å¹³å‡ ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {np.mean([r['sharpe_ratio'] for r in results]):.2f}")
```

## é«˜åº¦ãªä½¿ç”¨æ³•

### 1. ã‚«ã‚¹ã‚¿ãƒ ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã®ä½œæˆ

```python
import torch
import torch.nn as nn
from src.models.domain_blocks import DomainBlock

class CustomTechnicalIndicatorBlock(DomainBlock):
    """ã‚«ã‚¹ã‚¿ãƒ æŠ€è¡“æŒ‡æ¨™ãƒ–ãƒ­ãƒƒã‚¯"""
    
    def __init__(self, input_dim: int, indicator_types: List[str]):
        super().__init__("custom_technical", input_dim, input_dim + len(indicator_types))
        self.indicator_types = indicator_types
        self.indicator_nets = nn.ModuleList([
            nn.Linear(input_dim, 1) for _ in indicator_types
        ])
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        indicators = []
        for net in self.indicator_nets:
            indicator = net(x)
            indicators.append(indicator)
        
        indicators_tensor = torch.cat(indicators, dim=-1)
        return torch.cat([x, indicators_tensor], dim=-1)
    
    def get_complexity(self) -> int:
        return sum(p.numel() for p in self.parameters())

# ã‚«ã‚¹ã‚¿ãƒ ãƒ–ãƒ­ãƒƒã‚¯ã®ç™»éŒ²
from src.models.domain_blocks_registry import register_block
register_block("CustomTechnicalIndicatorBlock", CustomTechnicalIndicatorBlock)
```

### 2. ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡æŒ‡æ¨™ã®å®šç¾©

```python
from src.evaluation.custom_metrics import CustomMetric

class InformationRatioMetric(CustomMetric):
    """æƒ…å ±æ¯”ç‡ã®è¨ˆç®—"""
    
    def __init__(self, benchmark_returns: pd.Series):
        self.benchmark_returns = benchmark_returns
    
    def calculate(self, strategy_returns: pd.Series) -> float:
        excess_returns = strategy_returns - self.benchmark_returns
        return excess_returns.mean() / excess_returns.std() * np.sqrt(252)

# ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡ã®å®Ÿè¡Œ
topix_returns = load_benchmark_returns("^TPX")  # TOPIX
ir_metric = InformationRatioMetric(topix_returns)

for result in results:
    ir = ir_metric.calculate(result['daily_returns'])
    result['information_ratio'] = ir
    print(f"{result['model_name']}: IR = {ir:.2f}")
```

### 3. å‹•çš„ãƒªãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°æˆ¦ç•¥

```python
class DynamicRebalancingStrategy:
    """å‹•çš„ãƒªãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°æˆ¦ç•¥"""
    
    def __init__(self, volatility_lookback: int = 20):
        self.volatility_lookback = volatility_lookback
    
    def get_rebalance_frequency(self, market_volatility: float) -> str:
        """å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«åŸºã¥ã„ã¦ãƒªãƒãƒ©ãƒ³ã‚¹é »åº¦ã‚’æ±ºå®š"""
        if market_volatility > 0.3:
            return 'daily'
        elif market_volatility > 0.2:
            return 'weekly'
        else:
            return 'monthly'
    
    def adjust_position_sizes(self, predictions: pd.DataFrame, 
                            current_volatility: float) -> pd.DataFrame:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«åŸºã¥ã„ã¦ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã‚’èª¿æ•´"""
        volatility_scalar = 0.15 / current_volatility  # ç›®æ¨™ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£15%
        adjusted_predictions = predictions * volatility_scalar
        return adjusted_predictions.clip(-0.05, 0.05)  # Â±5%ã«åˆ¶é™

# å‹•çš„æˆ¦ç•¥ã®é©ç”¨
dynamic_strategy = DynamicRebalancingStrategy()
dynamic_backtest_config = backtest_config.copy()
dynamic_backtest_config['rebalancing_strategy'] = dynamic_strategy

dynamic_result = backtester.run_backtest(model, test_data, dynamic_backtest_config)
```

### 4. å®Ÿé¨“ã®è‡ªå‹•åŒ–

```python
from src.experiments.experiment_automation import ExperimentAutomator

# å®Ÿé¨“è‡ªå‹•åŒ–ã®è¨­å®š
automation_config = {
    'parameter_ranges': {
        'learning_rate': [0.0001, 0.001, 0.01],
        'batch_size': [16, 32, 64],
        'num_architectures': [25, 50, 100]
    },
    'evaluation_metric': 'sharpe_ratio',
    'optimization_budget': 50,  # 50å›ã®å®Ÿé¨“
    'early_stopping_patience': 10
}

# è‡ªå‹•å®Ÿé¨“ã®å®Ÿè¡Œ
automator = ExperimentAutomator(automation_config)
best_config = automator.optimize_hyperparameters()

print(f"æœ€é©è¨­å®š: {best_config}")
print(f"æœ€é«˜æ€§èƒ½: {best_config['best_score']:.3f}")
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºæ³•

#### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼
```python
# å•é¡Œ: "CUDA out of memory" ã‚¨ãƒ©ãƒ¼
# è§£æ±ºæ³•: ãƒãƒƒãƒã‚µã‚¤ã‚ºã®èª¿æ•´
config.training_config['batch_size'] = 16  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®32ã‹ã‚‰å‰Šæ¸›

# ã¾ãŸã¯GPUãƒ¡ãƒ¢ãƒªã®ç›£è¦–
import torch
print(f"GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
print(f"GPU ãƒ¡ãƒ¢ãƒªç·é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
```

#### ãƒ‡ãƒ¼ã‚¿åé›†ã®å¤±æ•—
```python
# å•é¡Œ: APIåˆ¶é™ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
# è§£æ±ºæ³•: ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ããƒ‡ãƒ¼ã‚¿åé›†
from src.data.robust_collector import RobustDataCollector

robust_collector = RobustDataCollector(
    max_retries=3,
    retry_delay=60,  # 60ç§’å¾…æ©Ÿ
    fallback_sources=['yahoo', 'alternative_api']
)

data = robust_collector.collect_with_fallback(symbols, start_date, end_date)
```

#### è¨“ç·´ã®åæŸã—ãªã„å•é¡Œ
```python
# å•é¡Œ: ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ãªã„
# è§£æ±ºæ³•: å­¦ç¿’ç‡ã®èª¿æ•´ã¨æ—©æœŸåœæ­¢
training_config_fixed = {
    'learning_rate': 0.0001,  # ã‚ˆã‚Šå°ã•ãªå­¦ç¿’ç‡
    'scheduler': 'reduce_on_plateau',
    'early_stopping': {
        'enabled': True,
        'patience': 20,
        'restore_best_weights': True
    }
}
```

### 2. ãƒ‡ãƒãƒƒã‚°ã¨ãƒ­ã‚°ç¢ºèª

#### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®èª¿æ•´
```python
import logging

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®æœ‰åŠ¹åŒ–
logging.basicConfig(level=logging.DEBUG)

# ç‰¹å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
logging.getLogger('src.agents').setLevel(logging.DEBUG)
logging.getLogger('src.training').setLevel(logging.INFO)
```

#### ä¸­é–“çµæœã®ä¿å­˜ã¨ç¢ºèª
```python
# è¨“ç·´é€”ä¸­ã§ã®ãƒ¢ãƒ‡ãƒ«ä¿å­˜
class DebuggingTrainer(ModelTrainer):
    def train_model(self, architecture, train_data, val_data):
        # å„ã‚¨ãƒãƒƒã‚¯å¾Œã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
        for epoch in range(self.config['epochs']):
            # è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—
            train_loss = self.train_epoch(model, train_data)
            val_loss = self.validate_epoch(model, val_data)
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
            if epoch % 10 == 0:
                torch.save(model.state_dict(), f'checkpoint_epoch_{epoch}.pth')
                print(f"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
```

### 3. æ€§èƒ½å•é¡Œã®è¨ºæ–­

```python
import cProfile
import pstats

def profile_experiment():
    """å®Ÿé¨“ã®æ€§èƒ½ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ã®é–‹å§‹
    profiler = cProfile.Profile()
    profiler.enable()
    
    # å®Ÿé¨“å®Ÿè¡Œ
    agent = ArchitectureAgent(config)
    architectures = agent.generate_architectures(
        input_shape=(32, 252, 20),
        num_architectures=10
    )
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ã®åœæ­¢
    profiler.disable()
    
    # çµæœã®è¡¨ç¤º
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # ä¸Šä½20å€‹ã®é–¢æ•°ã‚’è¡¨ç¤º

# æ€§èƒ½åˆ†æã®å®Ÿè¡Œ
profile_experiment()
```

### 4. ã‚ˆãã‚ã‚‹è³ªå• (FAQ)

#### Q: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¾ã™
```python
# A: ä¸¦åˆ—ç”Ÿæˆã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨
agent_config = {
    'parallel_generation': True,
    'max_workers': 4,
    'cache_enabled': True,
    'generation_timeout': 1800  # 30åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
}

agent = ArchitectureAgent(agent_config)
```

#### Q: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãŒç¾å®Ÿçš„ã§ãªã„
```python
# A: ã‚ˆã‚Šç¾å®Ÿçš„ãªå–å¼•ã‚³ã‚¹ãƒˆã¨åˆ¶ç´„ã®è¨­å®š
realistic_config = {
    'transaction_costs': {
        'commission_rate': 0.002,  # 0.2%
        'market_impact': 0.001,   # 0.1%
        'bid_ask_spread': 0.0005  # 0.05%
    },
    'position_constraints': {
        'max_position_size': 0.01,    # 1%åˆ¶é™
        'max_turnover': 2.0,          # å¹´é–“200%
        'liquidity_filter': True      # æµå‹•æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    }
}
```

#### Q: MLflowã§å®Ÿé¨“ãŒè¿½è·¡ã§ããªã„
```python
# A: MLflowè¨­å®šã®ç¢ºèªã¨ä¿®æ­£
import mlflow

# æ¥ç¶šç¢ºèª
try:
    mlflow.get_tracking_uri()
    print("MLflowæ¥ç¶šOK")
except Exception as e:
    print(f"MLflowæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«åˆ‡ã‚Šæ›¿ãˆ
    mlflow.set_tracking_uri("file:./mlruns")
```

## ã¾ã¨ã‚

Alpha Architecture Agentã¯ã€é‡‘èæ™‚ç³»åˆ—äºˆæ¸¬ã®ãŸã‚ã®å¼·åŠ›ã§æŸ”è»Ÿãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚æœ¬ã‚¬ã‚¤ãƒ‰ã§èª¬æ˜ã—ãŸåŸºæœ¬æ“ä½œã‹ã‚‰é«˜åº¦ãªä½¿ç”¨æ³•ã¾ã§ã€æ®µéšçš„ã«ç¿’å¾—ã™ã‚‹ã“ã¨ã§ã€åŠ¹æœçš„ãªæŠ•è³‡æˆ¦ç•¥ã®é–‹ç™ºãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚

### æ¨å¥¨å­¦ç¿’ãƒ‘ã‚¹
1. **åˆå¿ƒè€…**: ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ â†’ åŸºæœ¬æ“ä½œ â†’ ç°¡å˜ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
2. **ä¸­ç´šè€…**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ â†’ ãƒ¢ãƒ‡ãƒ«è¨“ç·´ â†’ çµæœåˆ†æ
3. **ä¸Šç´šè€…**: ã‚«ã‚¹ã‚¿ãƒ ãƒ–ãƒ­ãƒƒã‚¯ä½œæˆ â†’ å®Ÿé¨“è‡ªå‹•åŒ– â†’ æœ¬ç•ªé‹ç”¨

### ã‚µãƒãƒ¼ãƒˆãƒªã‚½ãƒ¼ã‚¹
- ğŸ“š è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: `docs/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- ğŸ’» ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰: `examples/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª  
- ğŸ“Š Jupyter Notebook: `notebooks/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- ğŸ› Issues: GitHub Issues
- ğŸ’¬ ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£: Discord ã‚µãƒ¼ãƒãƒ¼

ã”ä¸æ˜ãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚