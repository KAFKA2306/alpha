# ユーザーガイド

## 概要
Alpha Architecture Agentの使用方法について、初心者から上級者まで段階的に説明いたします。本ガイドでは、システムの基本操作から高度な実験設定まで、実用的な例を交えて解説しております。

## 目次
1. [クイックスタート](#クイックスタート)
2. [基本操作](#基本操作)
3. [アーキテクチャ生成](#アーキテクチャ生成)
4. [モデル訓練](#モデル訓練)
5. [バックテスト](#バックテスト)
6. [結果分析](#結果分析)
7. [高度な使用法](#高度な使用法)
8. [トラブルシューティング](#トラブルシューティング)

## クイックスタート

### 5分で始める Alpha Architecture Agent

#### ステップ1: 環境確認
```bash
# Pythonバージョンの確認
python --version  # 3.11以上であることを確認

# 必要なパッケージの確認
pip list | grep -E "(torch|pandas|numpy)"
```

#### ステップ2: 設定ファイルの準備
```bash
# サンプル設定をコピー
cp config/config.yaml.example config/config.yaml

# 最小限の設定を確認
cat config/config.yaml
```

#### ステップ3: 簡単なデモ実行
```bash
# デモスクリプトの実行
python examples/demo_architecture_generation.py

# 結果確認
ls results/
```

#### ステップ4: Webインターフェースの起動
```bash
# APIサーバーの起動
uvicorn src.api.main:app --reload

# ブラウザでアクセス
# http://localhost:8000/docs
```

これで基本的なセットアップが完了し、Alpha Architecture Agentを使い始めることができます。

## 基本操作

### 1. コマンドラインインターフェース

#### 基本コマンド
```bash
# ヘルプ表示
python -m src.cli --help

# システム状況確認
python -m src.cli status

# 設定確認
python -m src.cli config show
```

#### データ収集
```bash
# 日本株データの収集
python -m src.cli data collect \
  --symbols "7203.T,9984.T,6758.T" \
  --start-date "2023-01-01" \
  --end-date "2024-06-30"

# 収集状況の確認
python -m src.cli data status
```

### 2. Pythonスクリプトでの基本使用

#### 基本的な使用例
```python
from src.agents.architecture_agent import ArchitectureAgent
from src.core.config import Config

# 設定の読み込み
config = Config.from_yaml('config/config.yaml')

# エージェントの初期化
agent = ArchitectureAgent(config)

# アーキテクチャの生成
architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=10
)

print(f"生成されたアーキテクチャ数: {len(architectures)}")
for i, arch in enumerate(architectures):
    print(f"{i+1}. {arch['name']}: 複雑度 {arch['complexity']}")
```

### 3. Jupyter Notebookでの使用

#### Notebookの起動
```bash
# Jupyter Notebookの起動
jupyter notebook notebooks/

# または Jupyter Lab
jupyter lab notebooks/
```

#### 基本的なNotebook例
```python
# notebooks/getting_started.ipynb

# セル1: 必要なライブラリのインポート
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.agents.architecture_agent import ArchitectureAgent
from src.core.config import Config

# セル2: 設定とエージェントの初期化
config = Config.from_yaml('../config/config.yaml')
agent = ArchitectureAgent(config)

# セル3: アーキテクチャ生成
architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=5
)

# セル4: 結果の可視化
complexity_scores = [arch['complexity'] for arch in architectures]
plt.figure(figsize=(10, 6))
plt.bar(range(len(complexity_scores)), complexity_scores)
plt.xlabel('アーキテクチャID')
plt.ylabel('複雑度スコア')
plt.title('生成されたアーキテクチャの複雑度分布')
plt.show()
```

## アーキテクチャ生成

### 1. AIエージェントによる生成

#### 基本的な生成
```python
from src.agents.architecture_agent import ArchitectureAgent

# エージェントの初期化
agent = ArchitectureAgent(config)

# アーキテクチャ生成
architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),  # (バッチ, 系列長, 特徴数)
    num_architectures=50,
    generation_mode='ai_agent'
)

# 生成結果の確認
for arch in architectures[:5]:  # 上位5つを表示
    print(f"名前: {arch['name']}")
    print(f"ブロック数: {len(arch['blocks'])}")
    print(f"複雑度: {arch['complexity']}")
    print("---")
```

#### カスタム制約での生成
```python
# 制約条件を指定
constraints = {
    'max_complexity': 15,
    'min_complexity': 5,
    'required_blocks': ['PCABlock', 'LSTMBlock'],
    'forbidden_blocks': ['TransformerBlock'],
    'max_parameters': 1000000
}

# 制約付き生成
constrained_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=30,
    constraints=constraints
)
```

### 2. ランダム生成との比較

```python
# AIエージェント生成
ai_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=25,
    generation_mode='ai_agent'
)

# ランダム生成
random_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=25,
    generation_mode='random'
)

# 多様性の比較
from src.utils.diversity import calculate_diversity

ai_diversity = calculate_diversity(ai_architectures)
random_diversity = calculate_diversity(random_architectures)

print(f"AIエージェント多様性: {ai_diversity:.3f}")
print(f"ランダム生成多様性: {random_diversity:.3f}")
```

### 3. ハイブリッド生成

```python
# AIエージェントとランダムの組み合わせ
hybrid_architectures = agent.generate_architectures(
    input_shape=(32, 252, 20),
    num_architectures=50,
    generation_mode='hybrid',
    ai_ratio=0.7  # 70%をAIエージェント、30%をランダム
)
```

## モデル訓練

### 1. 単一モデルの訓練

#### 基本的な訓練
```python
from src.training.model_trainer import ModelTrainer
from src.data.data_loader import DataLoader

# データの準備
data_loader = DataLoader(config.data_config)
train_data, val_data, test_data = data_loader.load_and_split_data()

# トレーナーの初期化
trainer = ModelTrainer(config.training_config)

# 単一アーキテクチャの訓練
architecture = architectures[0]  # 最初のアーキテクチャを使用
model = trainer.train_model(
    architecture=architecture,
    train_data=train_data,
    val_data=val_data
)

print(f"訓練完了: {model['name']}")
print(f"最終検証損失: {model['val_loss']:.4f}")
```

#### 詳細な訓練設定
```python
# カスタム訓練設定
training_config = {
    'epochs': 150,
    'batch_size': 64,
    'learning_rate': 0.0005,
    'weight_decay': 0.0001,
    'scheduler': 'cosine',
    'early_stopping': {
        'enabled': True,
        'patience': 15,
        'min_delta': 0.0001
    },
    'data_augmentation': {
        'noise_std': 0.01,
        'dropout_rate': 0.1
    }
}

# 詳細設定での訓練
detailed_trainer = ModelTrainer(training_config)
model = detailed_trainer.train_model(architecture, train_data, val_data)
```

### 2. 複数モデルの並列訓練

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def train_multiple_models(architectures, data):
    """複数モデルの並列訓練"""
    
    def train_single_model(architecture):
        trainer = ModelTrainer(config.training_config)
        return trainer.train_model(architecture, data['train'], data['val'])
    
    # 並列実行
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [
            executor.submit(train_single_model, arch) 
            for arch in architectures
        ]
        
        models = []
        for i, future in enumerate(futures):
            try:
                model = future.result()
                models.append(model)
                print(f"モデル {i+1}/{len(architectures)} 完了")
            except Exception as e:
                print(f"モデル {i+1} 訓練失敗: {e}")
                models.append(None)
    
    return [m for m in models if m is not None]

# 実行
models = await train_multiple_models(architectures[:10], {
    'train': train_data,
    'val': val_data
})
```

### 3. 訓練監視とログ

```python
# MLflowとの統合
import mlflow
import mlflow.pytorch

class MLflowTrainer(ModelTrainer):
    def train_model(self, architecture, train_data, val_data):
        with mlflow.start_run():
            # パラメータの記録
            mlflow.log_params({
                'architecture_name': architecture['name'],
                'num_blocks': len(architecture['blocks']),
                'complexity': architecture['complexity']
            })
            
            # 訓練実行
            model = super().train_model(architecture, train_data, val_data)
            
            # メトリクスの記録
            mlflow.log_metrics({
                'final_train_loss': model['train_loss'],
                'final_val_loss': model['val_loss'],
                'training_time': model['training_time']
            })
            
            # モデルの保存
            mlflow.pytorch.log_model(model['pytorch_model'], "model")
            
            return model

# MLflow統合訓練の実行
mlflow_trainer = MLflowTrainer(config.training_config)
models = [mlflow_trainer.train_model(arch, train_data, val_data) for arch in architectures[:5]]
```

## バックテスト

### 1. 基本的なバックテスト

```python
from src.backtesting.backtester import Backtester

# バックテスト設定
backtest_config = {
    'start_date': '2023-01-01',
    'end_date': '2024-06-30',
    'initial_capital': 10000000,  # 1000万円
    'long_percentage': 0.05,      # 上位5%をロング
    'short_percentage': 0.05,     # 下位5%をショート
    'rebalance_frequency': 'daily',
    'transaction_cost': 0.001     # 0.1%の取引コスト
}

# バックテスターの初期化
backtester = Backtester(backtest_config)

# 単一モデルのバックテスト
model = models[0]
result = backtester.run_backtest(model, test_data)

print(f"総収益率: {result['total_return']:.2%}")
print(f"シャープレシオ: {result['sharpe_ratio']:.2f}")
print(f"最大ドローダウン: {result['max_drawdown']:.2%}")
```

### 2. 複数モデルの比較バックテスト

```python
# 全モデルのバックテスト実行
results = []
for i, model in enumerate(models):
    result = backtester.run_backtest(model, test_data)
    result['model_id'] = i
    result['model_name'] = model['name']
    results.append(result)

# 結果の比較
import pandas as pd

comparison_df = pd.DataFrame([
    {
        'モデル名': r['model_name'],
        '総収益率': f"{r['total_return']:.2%}",
        'シャープレシオ': f"{r['sharpe_ratio']:.2f}",
        '最大ドローダウン': f"{r['max_drawdown']:.2%}",
        'カルマーレシオ': f"{r['calmar_ratio']:.2f}"
    }
    for r in results
])

print(comparison_df.sort_values('シャープレシオ', ascending=False))
```

### 3. 高度なバックテスト設定

```python
# リスク管理付きバックテスト
advanced_config = {
    'start_date': '2023-01-01',
    'end_date': '2024-06-30',
    'initial_capital': 10000000,
    'position_sizing': {
        'method': 'risk_parity',
        'target_volatility': 0.15,
        'max_position_size': 0.02,
        'sector_limit': 0.3
    },
    'risk_management': {
        'stop_loss': 0.05,
        'take_profit': 0.15,
        'max_drawdown_limit': 0.1
    },
    'transaction_costs': {
        'commission_rate': 0.001,
        'market_impact': 0.0005,
        'bid_ask_spread': 0.0002
    }
}

advanced_backtester = Backtester(advanced_config)
advanced_result = advanced_backtester.run_backtest(model, test_data)
```

## 結果分析

### 1. 性能分析

```python
from src.analysis.performance_analyzer import PerformanceAnalyzer

# 分析器の初期化
analyzer = PerformanceAnalyzer()

# 詳細分析の実行
analysis = analyzer.analyze_performance(results)

# 統計サマリー
print("=== 性能統計 ===")
print(f"平均シャープレシオ: {analysis['mean_sharpe']:.2f}")
print(f"シャープレシオ標準偏差: {analysis['std_sharpe']:.2f}")
print(f"最高シャープレシオ: {analysis['max_sharpe']:.2f}")
print(f"勝率: {analysis['win_rate']:.1%}")
```

### 2. 視覚化

```python
import matplotlib.pyplot as plt
import seaborn as sns

# 性能分布の可視化
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# シャープレシオの分布
axes[0, 0].hist([r['sharpe_ratio'] for r in results], bins=20, alpha=0.7)
axes[0, 0].set_title('シャープレシオの分布')
axes[0, 0].set_xlabel('シャープレシオ')
axes[0, 0].set_ylabel('頻度')

# 収益率vs最大ドローダウン
axes[0, 1].scatter(
    [r['max_drawdown'] for r in results],
    [r['total_return'] for r in results],
    alpha=0.7
)
axes[0, 1].set_title('収益率 vs 最大ドローダウン')
axes[0, 1].set_xlabel('最大ドローダウン')
axes[0, 1].set_ylabel('総収益率')

# 複雑度vs性能
complexities = [arch['complexity'] for arch in architectures]
sharpe_ratios = [r['sharpe_ratio'] for r in results]

axes[1, 0].scatter(complexities, sharpe_ratios, alpha=0.7)
axes[1, 0].set_title('アーキテクチャ複雑度 vs シャープレシオ')
axes[1, 0].set_xlabel('複雑度')
axes[1, 0].set_ylabel('シャープレシオ')

# 累積収益の時系列
best_result = max(results, key=lambda x: x['sharpe_ratio'])
cumulative_returns = (1 + best_result['daily_returns']).cumprod()

axes[1, 1].plot(cumulative_returns.index, cumulative_returns.values)
axes[1, 1].set_title('最高性能モデルの累積収益')
axes[1, 1].set_xlabel('日付')
axes[1, 1].set_ylabel('累積収益')

plt.tight_layout()
plt.show()
```

### 3. アンサンブル分析

```python
from src.ensemble.ensemble_manager import EnsembleManager

# アンサンブルマネージャーの初期化
ensemble_manager = EnsembleManager()

# 上位20モデルの選択
top_models = ensemble_manager.select_top_models(
    results=results,
    models=models,
    top_n=20,
    selection_criteria='sharpe_ratio',
    correlation_threshold=0.8
)

print(f"アンサンブル対象モデル数: {len(top_models)}")

# アンサンブルバックテスト
ensemble_result = backtester.run_ensemble_backtest(top_models, test_data)

print(f"アンサンブル シャープレシオ: {ensemble_result['sharpe_ratio']:.2f}")
print(f"個別モデル平均 シャープレシオ: {np.mean([r['sharpe_ratio'] for r in results]):.2f}")
```

## 高度な使用法

### 1. カスタムドメインブロックの作成

```python
import torch
import torch.nn as nn
from src.models.domain_blocks import DomainBlock

class CustomTechnicalIndicatorBlock(DomainBlock):
    """カスタム技術指標ブロック"""
    
    def __init__(self, input_dim: int, indicator_types: List[str]):
        super().__init__("custom_technical", input_dim, input_dim + len(indicator_types))
        self.indicator_types = indicator_types
        self.indicator_nets = nn.ModuleList([
            nn.Linear(input_dim, 1) for _ in indicator_types
        ])
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        indicators = []
        for net in self.indicator_nets:
            indicator = net(x)
            indicators.append(indicator)
        
        indicators_tensor = torch.cat(indicators, dim=-1)
        return torch.cat([x, indicators_tensor], dim=-1)
    
    def get_complexity(self) -> int:
        return sum(p.numel() for p in self.parameters())

# カスタムブロックの登録
from src.models.domain_blocks_registry import register_block
register_block("CustomTechnicalIndicatorBlock", CustomTechnicalIndicatorBlock)
```

### 2. カスタム評価指標の定義

```python
from src.evaluation.custom_metrics import CustomMetric

class InformationRatioMetric(CustomMetric):
    """情報比率の計算"""
    
    def __init__(self, benchmark_returns: pd.Series):
        self.benchmark_returns = benchmark_returns
    
    def calculate(self, strategy_returns: pd.Series) -> float:
        excess_returns = strategy_returns - self.benchmark_returns
        return excess_returns.mean() / excess_returns.std() * np.sqrt(252)

# カスタム評価の実行
topix_returns = load_benchmark_returns("^TPX")  # TOPIX
ir_metric = InformationRatioMetric(topix_returns)

for result in results:
    ir = ir_metric.calculate(result['daily_returns'])
    result['information_ratio'] = ir
    print(f"{result['model_name']}: IR = {ir:.2f}")
```

### 3. 動的リバランシング戦略

```python
class DynamicRebalancingStrategy:
    """動的リバランシング戦略"""
    
    def __init__(self, volatility_lookback: int = 20):
        self.volatility_lookback = volatility_lookback
    
    def get_rebalance_frequency(self, market_volatility: float) -> str:
        """市場ボラティリティに基づいてリバランス頻度を決定"""
        if market_volatility > 0.3:
            return 'daily'
        elif market_volatility > 0.2:
            return 'weekly'
        else:
            return 'monthly'
    
    def adjust_position_sizes(self, predictions: pd.DataFrame, 
                            current_volatility: float) -> pd.DataFrame:
        """ボラティリティに基づいてポジションサイズを調整"""
        volatility_scalar = 0.15 / current_volatility  # 目標ボラティリティ15%
        adjusted_predictions = predictions * volatility_scalar
        return adjusted_predictions.clip(-0.05, 0.05)  # ±5%に制限

# 動的戦略の適用
dynamic_strategy = DynamicRebalancingStrategy()
dynamic_backtest_config = backtest_config.copy()
dynamic_backtest_config['rebalancing_strategy'] = dynamic_strategy

dynamic_result = backtester.run_backtest(model, test_data, dynamic_backtest_config)
```

### 4. 実験の自動化

```python
from src.experiments.experiment_automation import ExperimentAutomator

# 実験自動化の設定
automation_config = {
    'parameter_ranges': {
        'learning_rate': [0.0001, 0.001, 0.01],
        'batch_size': [16, 32, 64],
        'num_architectures': [25, 50, 100]
    },
    'evaluation_metric': 'sharpe_ratio',
    'optimization_budget': 50,  # 50回の実験
    'early_stopping_patience': 10
}

# 自動実験の実行
automator = ExperimentAutomator(automation_config)
best_config = automator.optimize_hyperparameters()

print(f"最適設定: {best_config}")
print(f"最高性能: {best_config['best_score']:.3f}")
```

## トラブルシューティング

### 1. 一般的な問題と解決法

#### メモリ不足エラー
```python
# 問題: "CUDA out of memory" エラー
# 解決法: バッチサイズの調整
config.training_config['batch_size'] = 16  # デフォルトの32から削減

# またはGPUメモリの監視
import torch
print(f"GPU メモリ使用量: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
print(f"GPU メモリ総量: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
```

#### データ収集の失敗
```python
# 問題: API制限やネットワークエラー
# 解決法: リトライ機能付きデータ収集
from src.data.robust_collector import RobustDataCollector

robust_collector = RobustDataCollector(
    max_retries=3,
    retry_delay=60,  # 60秒待機
    fallback_sources=['yahoo', 'alternative_api']
)

data = robust_collector.collect_with_fallback(symbols, start_date, end_date)
```

#### 訓練の収束しない問題
```python
# 問題: モデルが収束しない
# 解決法: 学習率の調整と早期停止
training_config_fixed = {
    'learning_rate': 0.0001,  # より小さな学習率
    'scheduler': 'reduce_on_plateau',
    'early_stopping': {
        'enabled': True,
        'patience': 20,
        'restore_best_weights': True
    }
}
```

### 2. デバッグとログ確認

#### ログレベルの調整
```python
import logging

# デバッグモードの有効化
logging.basicConfig(level=logging.DEBUG)

# 特定モジュールのログレベル設定
logging.getLogger('src.agents').setLevel(logging.DEBUG)
logging.getLogger('src.training').setLevel(logging.INFO)
```

#### 中間結果の保存と確認
```python
# 訓練途中でのモデル保存
class DebuggingTrainer(ModelTrainer):
    def train_model(self, architecture, train_data, val_data):
        # 各エポック後にチェックポイント保存
        for epoch in range(self.config['epochs']):
            # 訓練ステップ
            train_loss = self.train_epoch(model, train_data)
            val_loss = self.validate_epoch(model, val_data)
            
            # チェックポイント保存
            if epoch % 10 == 0:
                torch.save(model.state_dict(), f'checkpoint_epoch_{epoch}.pth')
                print(f"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
```

### 3. 性能問題の診断

```python
import cProfile
import pstats

def profile_experiment():
    """実験の性能プロファイリング"""
    
    # プロファイラーの開始
    profiler = cProfile.Profile()
    profiler.enable()
    
    # 実験実行
    agent = ArchitectureAgent(config)
    architectures = agent.generate_architectures(
        input_shape=(32, 252, 20),
        num_architectures=10
    )
    
    # プロファイラーの停止
    profiler.disable()
    
    # 結果の表示
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # 上位20個の関数を表示

# 性能分析の実行
profile_experiment()
```

### 4. よくある質問 (FAQ)

#### Q: アーキテクチャ生成に時間がかかりすぎます
```python
# A: 並列生成とキャッシュの活用
agent_config = {
    'parallel_generation': True,
    'max_workers': 4,
    'cache_enabled': True,
    'generation_timeout': 1800  # 30分でタイムアウト
}

agent = ArchitectureAgent(agent_config)
```

#### Q: バックテスト結果が現実的でない
```python
# A: より現実的な取引コストと制約の設定
realistic_config = {
    'transaction_costs': {
        'commission_rate': 0.002,  # 0.2%
        'market_impact': 0.001,   # 0.1%
        'bid_ask_spread': 0.0005  # 0.05%
    },
    'position_constraints': {
        'max_position_size': 0.01,    # 1%制限
        'max_turnover': 2.0,          # 年間200%
        'liquidity_filter': True      # 流動性フィルター
    }
}
```

#### Q: MLflowで実験が追跡できない
```python
# A: MLflow設定の確認と修正
import mlflow

# 接続確認
try:
    mlflow.get_tracking_uri()
    print("MLflow接続OK")
except Exception as e:
    print(f"MLflow接続エラー: {e}")
    
    # ローカルファイルシステムに切り替え
    mlflow.set_tracking_uri("file:./mlruns")
```

## まとめ

Alpha Architecture Agentは、金融時系列予測のための強力で柔軟なフレームワークです。本ガイドで説明した基本操作から高度な使用法まで、段階的に習得することで、効果的な投資戦略の開発が可能となります。

### 推奨学習パス
1. **初心者**: クイックスタート → 基本操作 → 簡単なバックテスト
2. **中級者**: アーキテクチャ生成 → モデル訓練 → 結果分析
3. **上級者**: カスタムブロック作成 → 実験自動化 → 本番運用

### サポートリソース
- 📚 詳細ドキュメント: `docs/` ディレクトリ
- 💻 サンプルコード: `examples/` ディレクトリ  
- 📊 Jupyter Notebook: `notebooks/` ディレクトリ
- 🐛 Issues: GitHub Issues
- 💬 コミュニティ: Discord サーバー

ご不明な点がございましたら、お気軽にお問い合わせください。