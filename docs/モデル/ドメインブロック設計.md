# ドメインブロック設計

## 概要
Alpha Architecture Agentにおけるドメインブロック設計について詳細に解説いたします。ドメインブロックは金融時系列データに特化したニューラルネットワークの基本構成要素として設計されております。

## アーキテクチャ設計思想

### 設計原則
1. **モジュール性**: 各ブロックは独立した機能を持つ
2. **組み合わせ自由度**: 任意のブロックを組み合わせ可能
3. **金融ドメイン特化**: 株式予測に最適化された設計
4. **性能効率**: 計算コストと予測精度のバランス

### ブロック分類体系
```
ドメインブロック
├── 正規化ブロック (normalization)
├── 特徴抽出ブロック (feature_extraction)
├── 混合ブロック (mixing)
├── エンコーディングブロック (encoding)
├── 金融ドメインブロック (financial_domain)
├── 特徴統合ブロック (feature_integration)
├── 時間統合ブロック (time_integration)
├── 株式特徴ブロック (stock_features)
├── アテンションブロック (attention)
├── フィードフォワードブロック (feedforward)
├── 時間埋め込みブロック (time_embedding)
├── シーケンスモデルブロック (sequence_models)
└── 予測ヘッドブロック (prediction_heads)
```

## 各ブロックカテゴリ詳細

### 正規化ブロック (Normalization Blocks)

#### BatchNormBlock
```python
class BatchNormBlock(nn.Module):
    """バッチ正規化ブロック"""
    
    def __init__(self, num_features: int):
        super().__init__()
        self.bn = nn.BatchNorm1d(num_features)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.bn(x)
```

**特徴**:
- 標準的なバッチ正規化
- 学習の安定化
- 勾配消失問題の軽減

#### LayerNormBlock
```python
class LayerNormBlock(nn.Module):
    """レイヤー正規化ブロック"""
    
    def __init__(self, normalized_shape: int):
        super().__init__()
        self.ln = nn.LayerNorm(normalized_shape)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.ln(x)
```

**特徴**:
- Transformer様アーキテクチャに適用
- バッチサイズに依存しない正規化
- 時系列データに適している

#### AdaptiveInstanceNormBlock
```python
class AdaptiveInstanceNormBlock(nn.Module):
    """適応的インスタンス正規化ブロック"""
    
    def __init__(self, num_features: int):
        super().__init__()
        self.instance_norm = nn.InstanceNorm1d(num_features, affine=False)
        self.style_scale = nn.Parameter(torch.ones(num_features))
        self.style_bias = nn.Parameter(torch.zeros(num_features))
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        normalized = self.instance_norm(x)
        return self.style_scale.unsqueeze(-1) * normalized + self.style_bias.unsqueeze(-1)
```

**特徴**:
- 学習可能な正規化パラメータ
- 各銘柄の特性に適応
- 市場環境の変化に対応

#### DemeanBlock
```python
class DemeanBlock(nn.Module):
    """平均除去ブロック"""
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x - x.mean(dim=-1, keepdim=True)
```

**特徴**:
- シンプルな中心化
- 計算効率が高い
- 基本的な前処理として有効

### 特徴抽出ブロック (Feature Extraction Blocks)

#### PCABlock
```python
class PCABlock(nn.Module):
    """主成分分析ブロック"""
    
    def __init__(self, input_dim: int, n_components: int):
        super().__init__()
        self.input_dim = input_dim
        self.n_components = n_components
        self.linear = nn.Linear(input_dim, n_components)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.linear(x)
```

**特徴**:
- 次元削減
- 主要な変動要因の抽出
- ノイズ除去効果

#### FourierFeaturesBlock
```python
class FourierFeaturesBlock(nn.Module):
    """フーリエ特徴ブロック"""
    
    def __init__(self, input_dim: int, n_frequencies: int):
        super().__init__()
        self.frequencies = nn.Parameter(torch.randn(n_frequencies, input_dim))
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        proj = torch.matmul(x, self.frequencies.T)
        return torch.cat([torch.sin(proj), torch.cos(proj)], dim=-1)
```

**特徴**:
- 周波数ドメインの特徴抽出
- 周期性の捕捉
- 非線形変換

#### MultiTimeFrameBlock
```python
class MultiTimeFrameBlock(nn.Module):
    """マルチタイムフレームブロック"""
    
    def __init__(self, input_dim: int, time_frames: List[int]):
        super().__init__()
        self.time_frames = time_frames
        self.projections = nn.ModuleList([
            nn.Linear(input_dim, input_dim) for _ in time_frames
        ])
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x: [batch, seq_len, features]
        features = []
        for i, frame in enumerate(self.time_frames):
            pooled = F.avg_pool1d(x.transpose(1, 2), kernel_size=frame, stride=1, padding=frame//2)
            features.append(self.projections[i](pooled.transpose(1, 2)))
        return torch.cat(features, dim=-1)
```

**特徴**:
- 複数の時間スケール分析
- 短期・長期トレンドの統合
- 階層的特徴抽出

### 金融ドメインブロック (Financial Domain Blocks)

#### RegimeDetectionBlock
```python
class RegimeDetectionBlock(nn.Module):
    """市場レジーム検出ブロック"""
    
    def __init__(self, input_dim: int, n_regimes: int):
        super().__init__()
        self.n_regimes = n_regimes
        self.regime_detector = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, n_regimes)
        )
        self.regime_embeddings = nn.Parameter(torch.randn(n_regimes, input_dim))
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        regime_probs = F.softmax(self.regime_detector(x), dim=-1)
        regime_features = torch.matmul(regime_probs, self.regime_embeddings)
        return torch.cat([x, regime_features], dim=-1)
```

**特徴**:
- 市場環境の自動識別
- レジーム特有の特徴抽出
- 適応的な予測モデル

#### FactorExposureBlock
```python
class FactorExposureBlock(nn.Module):
    """ファクター露出ブロック"""
    
    def __init__(self, input_dim: int, n_factors: int):
        super().__init__()
        self.factor_loadings = nn.Parameter(torch.randn(n_factors, input_dim))
        self.factor_returns = nn.Parameter(torch.randn(n_factors))
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        exposures = torch.matmul(x, self.factor_loadings.T)
        factor_contributions = exposures * self.factor_returns.unsqueeze(0).unsqueeze(0)
        return torch.cat([x, factor_contributions], dim=-1)
```

**特徴**:
- リスクファクター分析
- 系統的リスクの分解
- ファクター露出の定量化

#### CrossSectionalBlock
```python
class CrossSectionalBlock(nn.Module):
    """クロスセクショナル分析ブロック"""
    
    def __init__(self, input_dim: int, n_stocks: int):
        super().__init__()
        self.stock_embeddings = nn.Parameter(torch.randn(n_stocks, input_dim))
        self.cross_attention = nn.MultiheadAttention(input_dim, 8)
    
    def forward(self, x: torch.Tensor, stock_indices: torch.Tensor) -> torch.Tensor:
        stock_embeds = self.stock_embeddings[stock_indices]
        attended, _ = self.cross_attention(x, stock_embeds, stock_embeds)
        return attended + x
```

**特徴**:
- 銘柄間の相互作用
- セクター効果の捕捉
- 相対価値分析

### シーケンスモデルブロック (Sequence Models)

#### LSTMBlock
```python
class LSTMBlock(nn.Module):
    """LSTM ブロック"""
    
    def __init__(self, input_dim: int, hidden_dim: int, num_layers: int = 1):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.output_proj = nn.Linear(hidden_dim, input_dim)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        lstm_out, _ = self.lstm(x)
        return self.output_proj(lstm_out)
```

**特徴**:
- 長期記憶の捕捉
- 系列依存性の学習
- 時系列予測に適用

#### TransformerBlock
```python
class TransformerBlock(nn.Module):
    """Transformer ブロック"""
    
    def __init__(self, input_dim: int, n_heads: int = 8, ff_dim: int = 2048):
        super().__init__()
        self.attention = nn.MultiheadAttention(input_dim, n_heads)
        self.norm1 = nn.LayerNorm(input_dim)
        self.ff = nn.Sequential(
            nn.Linear(input_dim, ff_dim),
            nn.ReLU(),
            nn.Linear(ff_dim, input_dim)
        )
        self.norm2 = nn.LayerNorm(input_dim)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Self-attention
        attn_out, _ = self.attention(x, x, x)
        x = self.norm1(x + attn_out)
        
        # Feed-forward
        ff_out = self.ff(x)
        x = self.norm2(x + ff_out)
        
        return x
```

**特徴**:
- 自己注意機構
- 並列処理可能
- 長距離依存性の捕捉

### 予測ヘッドブロック (Prediction Heads)

#### RankingHead
```python
class RankingHead(nn.Module):
    """ランキング予測ヘッド"""
    
    def __init__(self, input_dim: int):
        super().__init__()
        self.ranking_net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.ranking_net(x)
```

**特徴**:
- 相対的順位予測
- ペアワイズ比較学習
- ロング・ショート戦略に適用

#### VolatilityHead
```python
class VolatilityHead(nn.Module):
    """ボラティリティ予測ヘッド"""
    
    def __init__(self, input_dim: int):
        super().__init__()
        self.vol_net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Softplus()  # 正の値を保証
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.vol_net(x)
```

**特徴**:
- リスク量の予測
- 不確実性の定量化
- リスク調整リターン

## ブロック設計パターン

### 基本インターフェース
```python
class DomainBlock(nn.Module):
    """ドメインブロックの基底クラス"""
    
    def __init__(self, block_name: str, input_dim: int, output_dim: int):
        super().__init__()
        self.block_name = block_name
        self.input_dim = input_dim
        self.output_dim = output_dim
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        raise NotImplementedError
    
    def get_complexity(self) -> int:
        """ブロックの複雑度を返す"""
        return sum(p.numel() for p in self.parameters())
```

### 組み合わせ可能性
```python
class CompositeBlock(nn.Module):
    """複数のブロックを組み合わせる"""
    
    def __init__(self, blocks: List[DomainBlock]):
        super().__init__()
        self.blocks = nn.ModuleList(blocks)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        for block in self.blocks:
            x = block(x)
        return x
```

### 残差接続
```python
class ResidualBlock(nn.Module):
    """残差接続を持つブロック"""
    
    def __init__(self, block: DomainBlock):
        super().__init__()
        self.block = block
        self.adaptation = nn.Linear(block.input_dim, block.output_dim) if block.input_dim != block.output_dim else nn.Identity()
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.block(x) + self.adaptation(x)
```

## 性能評価指標

### 計算効率性
- **パラメータ数**: モデルのサイズ
- **FLOPS**: 浮動小数点演算数
- **メモリ使用量**: 推論時のメモリ要求

### 予測性能
- **シャープレシオ**: リスク調整後収益
- **最大ドローダウン**: 最大損失幅
- **情報比**: 超過収益の一貫性

### 多様性指標
- **アーキテクチャ多様性**: 構造的な違い
- **予測多様性**: 予測結果の相関

## 実装例

### カスタムブロック作成
```python
class CustomFinancialBlock(DomainBlock):
    """カスタム金融ブロック"""
    
    def __init__(self, input_dim: int, lookback_window: int = 20):
        super().__init__("custom_financial", input_dim, input_dim + 5)
        self.lookback_window = lookback_window
        
        # 技術指標計算
        self.ma_short = nn.AvgPool1d(5)
        self.ma_long = nn.AvgPool1d(20)
        
        # 特徴統合
        self.feature_combiner = nn.Linear(input_dim + 2, input_dim + 5)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # 移動平均計算
        ma_short = self.ma_short(x.transpose(1, 2)).transpose(1, 2)
        ma_long = self.ma_long(x.transpose(1, 2)).transpose(1, 2)
        
        # 特徴量統合
        combined = torch.cat([x[:, -ma_short.size(1):, :], ma_short, ma_long], dim=-1)
        
        return self.feature_combiner(combined)
```

### ブロック組み合わせ例
```python
def create_sample_architecture():
    """サンプルアーキテクチャの作成"""
    blocks = [
        DemeanBlock(),
        PCABlock(input_dim=20, n_components=15),
        LSTMBlock(input_dim=15, hidden_dim=64),
        RegimeDetectionBlock(input_dim=15, n_regimes=3),
        TransformerBlock(input_dim=18),
        RankingHead(input_dim=18)
    ]
    
    return CompositeBlock(blocks)
```

## 今後の拡張予定

### 新しいブロックタイプ
1. **グラフニューラルネットワーク**: セクター間関係の学習
2. **強化学習ブロック**: 適応的戦略選択
3. **メタ学習ブロック**: 新しい市場環境への適応

### 自動化機能
1. **自動ブロック選択**: 性能に基づくブロック選択
2. **アーキテクチャ最適化**: 進化的アルゴリズム
3. **動的ブロック調整**: 市場環境の変化に応じた調整

このドメインブロック設計により、効果的で柔軟性の高い株式予測モデルの構築が可能となります。